{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SegmentationDataset, SegmentationDatasetWithRandomCrops\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset, Subset\n",
    "import os\n",
    "from torchvision.transforms import Compose, ToTensor, Grayscale, Resize, v2, Normalize, CenterCrop, InterpolationMode\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "train_image_path = './FIVES/train/Original'\n",
    "train_label_path = './FIVES/train/GroundTruth'\n",
    "test_image_path = './FIVES/test/Original'\n",
    "test_label_path = './FIVES/test/GroundTruth'\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define transformations for images\n",
    "width, height = 512, 512\n",
    "image_transform = Compose([\n",
    "    Grayscale(num_output_channels=1),  # Convert the image to grayscale\n",
    "    Resize((width, height), InterpolationMode.BICUBIC),                # Resize images to 512x512\n",
    "    ToTensor(),                         # Convert the image to a PyTorch tensor\n",
    "    Normalize(mean=[0.2147], std=[0.1163])   # Normalize the grayscale image\n",
    "    # Normalize(mean=[0.3728, 0.1666, 0.0678], std=[0.1924, 0.0956, 0.0395])\n",
    "])\n",
    "\n",
    "# Define transformations for labels, if needed\n",
    "label_transform = Compose([\n",
    "    Resize((width, height), interpolation=InterpolationMode.NEAREST_EXACT),  # Resize labels to 512x512\n",
    "    ToTensor()           # Convert label to a tensor\n",
    "])\n",
    "\n",
    "augmentation = v2.RandomApply([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.RandomRotation(degrees=90),\n",
    "    v2.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "])\n",
    "\n",
    "random_crop_image_transform = Compose([\n",
    "    Grayscale(num_output_channels=1),\n",
    "    ToTensor()\n",
    "])\n",
    "random_crop_label_transform = Compose([ToTensor()])\n",
    "\n",
    "random_crop_dataset = SegmentationDatasetWithRandomCrops(\n",
    "    train_image_path, \n",
    "    train_label_path, \n",
    "    random_crop_image_transform, \n",
    "    random_crop_label_transform,\n",
    "    crop_width=width,\n",
    "    crop_height=height)\n",
    "\n",
    "dataset = SegmentationDataset(\n",
    "    train_image_path, \n",
    "    train_label_path, \n",
    "    image_transform, \n",
    "    label_transform,\n",
    ")\n",
    "\n",
    "testset = SegmentationDataset(\n",
    "    test_image_path, \n",
    "    test_label_path, \n",
    "    image_transform, \n",
    "    label_transform\n",
    ")\n",
    "\n",
    "augmented_dataset = SegmentationDataset(\n",
    "    train_image_path, \n",
    "    train_label_path, \n",
    "    image_transform, \n",
    "    label_transform,\n",
    "    augmentation\n",
    ")\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_size, val_size = int(0.9 * len(dataset)), int(0.1 * len(dataset) + 1)\n",
    "train_indices = np.random.choice(len(dataset), train_size, replace=False)\n",
    "val_indices = np.setdiff1d(np.arange(len(dataset)), train_indices)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "augmented_dataset = Subset(augmented_dataset, train_indices[:int(0.1 * len(train_indices))])\n",
    "random_crop_dataset = Subset(random_crop_dataset, train_indices[:int(0.1 * len(train_indices))])\n",
    "\n",
    "train_dataset = ConcatDataset([train_dataset, random_crop_dataset, augmented_dataset])\n",
    "print(f'Number of samples in the training set: {len(train_dataset)}, validation set: {len(val_dataset)}')\n",
    "print(f'Number of samples in the test set: {len(testset)}')\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=8)\n",
    "validationloader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=8)\n",
    "testloader = DataLoader(testset, batch_size=16, shuffle=False, num_workers=8)\n",
    "\n",
    "print(len(trainloader), len(validationloader), len(testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(images, labels, num_images=5):\n",
    "    fig, axs = plt.subplots(nrows=num_images, ncols=2, figsize=(10, num_images * 5))\n",
    "    for i in range(num_images):\n",
    "        img = images[i].numpy().transpose((1, 2, 0))  # Convert from PyTorch tensor format and channel first to channel last\n",
    "        lbl = labels[i].numpy().squeeze()            # Remove extra dimensions\n",
    "        if num_images == 1:\n",
    "            ax_img = axs[0]\n",
    "            ax_lbl = axs[1]\n",
    "        else:\n",
    "            ax_img = axs[i, 0]\n",
    "            ax_lbl = axs[i, 1]\n",
    "        \n",
    "        ax_img.imshow(img, cmap='gray')\n",
    "        ax_img.set_title('Fundus')\n",
    "        ax_img.axis('off')\n",
    "        \n",
    "        ax_lbl.imshow(lbl, cmap='gray')\n",
    "        ax_lbl.set_title('Segmentation Map')\n",
    "        ax_lbl.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(*zip(*[testset[i] for i in range(1)]), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from segmentation_util import (\n",
    "    model_pipeline,\n",
    "    build_criterion,\n",
    "    build_optimizer,\n",
    "    build_segmentation_model,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define Hyperparameters\n",
    "encoder = \"resnet101\"\n",
    "architecture = \"Unet\"\n",
    "learning_rate = 0.0157\n",
    "epochs = 10\n",
    "loss = \"Dice\"\n",
    "optimizer = \"Adam\"\n",
    "in_channels = 1\n",
    "gamma = 2\n",
    "\n",
    "config = {\n",
    "    \"model\": \"{architecture}-{encoder}-{width}x{height}-resized-grayscale\".format(\n",
    "        architecture=architecture, width=width, height=height, encoder=encoder\n",
    "    ),\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": trainloader.batch_size,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"criterion\": loss,\n",
    "    \"encoder\": encoder,\n",
    "    \"architecture\": architecture,\n",
    "    \"gamma\": gamma,\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = build_segmentation_model(\n",
    "    encoder, architecture=config[\"architecture\"], device=device, in_channels=in_channels\n",
    ")\n",
    "optimizer = build_optimizer(\n",
    "    model, learning_rate=config[\"learning_rate\"], optimizer=config[\"optimizer\"]\n",
    ")\n",
    "criterion = build_criterion(config[\"criterion\"], gamma=gamma)\n",
    "\n",
    "model, train_losses, val_losses = model_pipeline(\n",
    "    model,\n",
    "    trainloader=trainloader,\n",
    "    validationloader=validationloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    project=\"fundus-segmentation\",\n",
    "    model_name=config[\"model\"],\n",
    "    epochs=config[\"epochs\"],\n",
    "    device=device,\n",
    "    config=config,\n",
    "    with_overlays=True,\n",
    ")\n",
    "\n",
    "# Plotting the training and validation loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Curves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "\n",
    "model = smp.Unet('resnet152', in_channels=1, classes=1)\n",
    "model.load_state_dict(torch.load('./models/Unet-resnet152-512x512-augmented-with-random-crops_epoch10.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_util import evaluate_model, predict\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def show_overlay(model, data, device):\n",
    "    prediction = predict(model, data[0], device)\n",
    "    image = data[1].cpu().numpy().squeeze()\n",
    "    image = np.stack([image, image, image], axis=-1)\n",
    "    overlay = np.zeros_like(image)\n",
    "    overlay[prediction.cpu().numpy().squeeze(0) == 1] = [0, 255, 0]\n",
    "    combined = cv2.addWeighted(image, 0.7, overlay, 0.3, 0)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(combined, cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis numbers and ticks\n",
    "    plt.show()\n",
    "        \n",
    "# show_overlay(model, val_dataset[0], device)\n",
    "# show_images(*zip(*[train_dataset[i] for i in range(5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "from segmentation_util import train_sweep\n",
    "\n",
    "sweep_config = {\n",
    "    'name': 'Fundus-Segmentation-Sweep',\n",
    "    'method': 'bayes',\n",
    "    'parameters': {\n",
    "        'encoder': {\n",
    "            'values': ['resnet152', 'resnext101_32x8d', 'timm-resnest269e', 'timm-regnetx_320', 'timm-regnety_320', 'senet154']\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            \"min\": 0.00001, \n",
    "            \"max\": 0.1\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': 10\n",
    "        },\n",
    "        'loss': {\n",
    "            'values': ['Dice', 'BCE']\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['Adam', 'SGD']\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'value': 8\n",
    "        },\n",
    "        'proportion_augmented_data': {\n",
    "            'values': [0.1, 0.2, 0.3]\n",
    "        },\n",
    "        'architecture': {\n",
    "            'values': ['Unet', 'UnetPlusPlus']\n",
    "        }\n",
    "    },\n",
    "    'metric': {\n",
    "        'name': 'dice_score',\n",
    "        'goal': 'maximize'\n",
    "    }\n",
    "}\n",
    "sweep_config['parameters']['device'] = {'value':'cuda:0' if torch.cuda.is_available() else 'cpu'}\n",
    "sweep_id = wandb.sweep(sweep_config, project='fundus-segmentation')\n",
    "wandb.agent(sweep_id, function=train_sweep, count=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
