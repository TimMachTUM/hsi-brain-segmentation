{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spectral\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from dataset import HSIDataset\n",
    "\n",
    "path = '../../home/ivan/HELICoiD/HSI_Human_Brain_Database_IEEE_Access/'\n",
    "\n",
    "dataset = HSIDataset(path)\n",
    "dataset.normalize_dataset()\n",
    "\n",
    "train_indices = list(range(0, 19))\n",
    "val_indices = list(range(19, 24))\n",
    "test_indices = list(range(24, 36))\n",
    "\n",
    "trainset = Subset(dataset, train_indices)\n",
    "valset = Subset(dataset, val_indices)\n",
    "testset = Subset(dataset, test_indices)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=1, shuffle=False)\n",
    "validationloader = DataLoader(valset, batch_size=1, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_labels(labels):\n",
    "    plt.imshow(labels.squeeze().numpy(), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "show_labels(trainset[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn as nn\n",
    "from util import model_pipeline\n",
    "import torch.nn.functional as F\n",
    "from HSI_Net import HyperspectralToGrayscale, CombinedModel, ConvolutionalReducer, Unet\n",
    "\n",
    "config = {\n",
    "    'model': 'Test-model',\n",
    "    'learnnig_rate': 0.001,\n",
    "    'epochs': 10,\n",
    "    'batch_size': 1,\n",
    "    'optimizer': 'Adam',\n",
    "    'criterion': 'BCELoss',\n",
    "}\n",
    "\n",
    "segmenter = smp.Unet('resnet34', in_channels=1, classes=1)\n",
    "segmenter.load_state_dict(torch.load('./models/Unet-resnet34-DiceLoss/Unet-resnet34-DiceLoss_epoch10.pth'))\n",
    "encoder = HyperspectralToGrayscale()\n",
    "model = CombinedModel(encoder, segmenter)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learnnig_rate'])\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from util import model_pipeline\n",
    "\n",
    "\n",
    "model, train_losses, val_losses = model_pipeline(model, trainloader=trainloader, \n",
    "                                                 validationloader=validationloader, \n",
    "                                                 testloader=testloader, criterion=criterion, \n",
    "                                                 optimizer=optimizer,project='hsi-segmentation',\n",
    "                                                 model_name=config['model'],\n",
    "                                                 device=device, config=config, \n",
    "                                                 batch_print=1)\n",
    "\n",
    "# Plotting the training and validation loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from HSI_Net import CombinedModel, HyperspectralToGrayscale, ConvolutionalReducer\n",
    "from util import predict, show_overlay\n",
    "import segmentation_models_pytorch as smp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "encoder = HyperspectralToGrayscale()\n",
    "segmenter = smp.Unet('resnet34', in_channels=1, classes=1)\n",
    "# segmenter.load_state_dict(torch.load('./models/Unet-resnet34-DiceLoss/Unet-resnet34-DiceLoss_epoch10.pth'))\n",
    "model = CombinedModel(encoder, segmenter)\n",
    "model.load_state_dict(torch.load('./models/ConvLayer-Unet-resnet34/ConvLayer-Unet-resnet34_epoch10.pth'))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "show_overlay(model, trainset[0], device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
