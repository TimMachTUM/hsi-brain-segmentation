{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SegmentationDataset, SegmentationDatasetWithRandomCrops\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset, Subset\n",
    "import os\n",
    "from torchvision.transforms import Compose, ToTensor, Grayscale, Resize, v2, Normalize\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "train_image_path = './FIVES/train/Original'\n",
    "train_label_path = './FIVES/train/GroundTruth'\n",
    "test_image_path = './FIVES/test/Original'\n",
    "test_label_path = './FIVES/test/GroundTruth'\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define transformations for images\n",
    "width, height = 512, 512\n",
    "image_transform = Compose([\n",
    "    Grayscale(num_output_channels=1),  # Convert the image to grayscale\n",
    "    Resize((width, height)),                # Resize images to 512x512\n",
    "    ToTensor(),                         # Convert the image to a PyTorch tensor\n",
    "    Normalize(mean=[0.2147], std=[0.1163])   # Normalize the grayscale image\n",
    "    # Normalize(mean=[0.3728, 0.1666, 0.0678], std=[0.1924, 0.0956, 0.0395])\n",
    "])\n",
    "\n",
    "# Define transformations for labels, if needed\n",
    "label_transform = Compose([\n",
    "    Resize((width, height)),  # Resize labels to 512x512\n",
    "    ToTensor()           # Convert label to a tensor\n",
    "])\n",
    "\n",
    "augmentation = v2.RandomApply([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.RandomRotation(degrees=90),\n",
    "    v2.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "])\n",
    "\n",
    "random_crop_image_transform = Compose([\n",
    "    Grayscale(num_output_channels=1),\n",
    "    ToTensor()\n",
    "])\n",
    "random_crop_label_transform = Compose([ToTensor()])\n",
    "\n",
    "random_crop_dataset = SegmentationDatasetWithRandomCrops(\n",
    "    train_image_path, \n",
    "    train_label_path, \n",
    "    random_crop_image_transform, \n",
    "    random_crop_label_transform,\n",
    "    crop_width=width,\n",
    "    crop_height=height)\n",
    "\n",
    "dataset = SegmentationDataset(\n",
    "    train_image_path, \n",
    "    train_label_path, \n",
    "    image_transform, \n",
    "    label_transform,\n",
    ")\n",
    "\n",
    "testset = SegmentationDataset(\n",
    "    test_image_path, \n",
    "    test_label_path, \n",
    "    image_transform, \n",
    "    label_transform\n",
    ")\n",
    "\n",
    "augmented_dataset = SegmentationDataset(\n",
    "    train_image_path, \n",
    "    train_label_path, \n",
    "    image_transform, \n",
    "    label_transform,\n",
    "    augmentation\n",
    ")\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_size, val_size = int(0.9 * len(dataset)), int(0.1 * len(dataset) + 1)\n",
    "train_indices = np.random.choice(len(dataset), train_size, replace=False)\n",
    "val_indices = np.setdiff1d(np.arange(len(dataset)), train_indices)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "augmented_dataset = Subset(augmented_dataset, train_indices[:int(0.1 * len(train_indices))])\n",
    "random_crop_dataset = Subset(random_crop_dataset, train_indices[:int(0.1 * len(train_indices))])\n",
    "\n",
    "train_dataset = ConcatDataset([train_dataset, random_crop_dataset, augmented_dataset])\n",
    "print(f'Number of samples in the training set: {len(train_dataset)}, validation set: {len(val_dataset)}')\n",
    "print(f'Number of samples in the test set: {len(testset)}')\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=8)\n",
    "validationloader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=8)\n",
    "testloader = DataLoader(testset, batch_size=8, shuffle=False, num_workers=8)\n",
    "\n",
    "print(len(trainloader), len(validationloader), len(testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(images, labels, num_images=5):\n",
    "    fig, axs = plt.subplots(nrows=num_images, ncols=2, figsize=(10, num_images * 5))\n",
    "    for i in range(num_images):\n",
    "        img = images[i].numpy().transpose((1, 2, 0))  # Convert from PyTorch tensor format and channel first to channel last\n",
    "        lbl = labels[i].numpy().squeeze()            # Remove extra dimensions\n",
    "        \n",
    "        if num_images == 1:\n",
    "            ax_img = axs[0]\n",
    "            ax_lbl = axs[1]\n",
    "        else:\n",
    "            ax_img = axs[i, 0]\n",
    "            ax_lbl = axs[i, 1]\n",
    "        \n",
    "        ax_img.imshow(img, cmap='gray')\n",
    "        ax_img.set_title('Fundus')\n",
    "        ax_img.axis('off')\n",
    "        \n",
    "        ax_lbl.imshow(lbl, cmap='gray')\n",
    "        ax_lbl.set_title('Segmentation Map')\n",
    "        ax_lbl.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(*zip(*[random_crop_dataset[i] for i in range(5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from segmentation_util import model_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "encoder = 'resnext101_32x8d'\n",
    "config = {\n",
    "    'model': 'UnetPlusPlus-{encoder}-{width}x{height}-augmented-with-random-crops-single-channel'.format(width=width, height=height, encoder=encoder),\n",
    "    'learnnig_rate': 0.001,\n",
    "    'epochs': 10,\n",
    "    'batch_size': trainloader.batch_size,\n",
    "    'optimizer': 'Adam',\n",
    "    'criterion': 'Dice',\n",
    "}\n",
    "\n",
    "model = smp.UnetPlusPlus(encoder_name=encoder, in_channels=1, classes=1, encoder_weights=None)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learnnig_rate'])\n",
    "criterion = smp.losses.DiceLoss(mode='binary')\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model, train_losses, val_losses = model_pipeline(model, trainloader=trainloader, \n",
    "                                                 validationloader=validationloader, \n",
    "                                                 testloader=testloader, \n",
    "                                                 criterion=criterion, \n",
    "                                                 optimizer=optimizer,\n",
    "                                                 project='fundus-segmentation',\n",
    "                                                 model_name=config['model'],\n",
    "                                                 epochs=config['epochs'],\n",
    "                                                 device=device, \n",
    "                                                 config=config)\n",
    "\n",
    "# Plotting the training and validation loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "\n",
    "model = smp.Unet('resnet152', in_channels=1, classes=1)\n",
    "model.load_state_dict(torch.load('./models/Unet-resnet152-512x512-augmented-with-random-crops_epoch10.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_util import evaluate_model, predict\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_overlay(model, data, device):\n",
    "    prediction = predict(model, data[0], device)\n",
    "    image = data[1].cpu().numpy().squeeze()\n",
    "    image = np.stack([image, image, image], axis=-1)\n",
    "    overlay = np.zeros_like(image)\n",
    "    overlay[prediction.cpu().numpy().squeeze(0) == 1] = [0, 255, 0]\n",
    "    combined = cv2.addWeighted(image, 0.7, overlay, 0.3, 0)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(combined, cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis numbers and ticks\n",
    "    plt.show()\n",
    "\n",
    "# device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "show_overlay(model, testset[0], device)\n",
    "# show_images(*zip(*[train_dataset[i] for i in range(5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: c7hg8g7l\n",
      "Sweep URL: https://wandb.ai/idp2024/fundus-segmentation/sweeps/c7hg8g7l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: awcalll8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: Unet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdevice: cuda:0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder: timm-resnest269e\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.020474544930357087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Dice\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tproportion_augmented_data: 0.2\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtim-mach\u001b[0m (\u001b[33midp2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tim_ivan/idp/wandb/run-20240701_201258-awcalll8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idp2024/fundus-segmentation/runs/awcalll8' target=\"_blank\">fearless-sweep-1</a></strong> to <a href='https://wandb.ai/idp2024/fundus-segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/idp2024/fundus-segmentation/sweeps/c7hg8g7l' target=\"_blank\">https://wandb.ai/idp2024/fundus-segmentation/sweeps/c7hg8g7l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idp2024/fundus-segmentation' target=\"_blank\">https://wandb.ai/idp2024/fundus-segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/idp2024/fundus-segmentation/sweeps/c7hg8g7l' target=\"_blank\">https://wandb.ai/idp2024/fundus-segmentation/sweeps/c7hg8g7l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idp2024/fundus-segmentation/runs/awcalll8' target=\"_blank\">https://wandb.ai/idp2024/fundus-segmentation/runs/awcalll8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 746, validation set: 60\n",
      "Number of samples in the test set: 200\n",
      "Epoch 1, Batch 10, Loss: 0.8252\n",
      "Epoch 1, Batch 20, Loss: 0.7957\n",
      "Epoch 1, Batch 30, Loss: 0.7917\n",
      "Epoch 1, Batch 40, Loss: 0.8016\n",
      "Epoch 1, Batch 50, Loss: 0.7954\n",
      "Epoch 1, Batch 60, Loss: 0.7898\n",
      "Epoch 1, Batch 70, Loss: 0.7967\n",
      "Epoch 1, Batch 80, Loss: 0.7852\n",
      "Epoch 1, Batch 90, Loss: 0.7901\n",
      "Epoch 1, Train Loss: 0.7972\n",
      "Epoch 1, Validation Loss: 0.8052\n",
      "Precision: 0.0483, Recall: 0.8737, F1 Score: 0.0914, Dice Score: 0.0914, Accuracy: 0.4629\n",
      "Epoch 2, Batch 10, Loss: 0.7820\n",
      "Epoch 2, Batch 20, Loss: 0.8019\n",
      "Epoch 2, Batch 30, Loss: 0.7926\n",
      "Epoch 2, Batch 40, Loss: 0.7997\n",
      "Epoch 2, Batch 50, Loss: 0.7841\n",
      "Epoch 2, Batch 60, Loss: 0.7613\n",
      "Epoch 2, Batch 70, Loss: 0.7471\n",
      "Epoch 2, Batch 80, Loss: 0.6654\n",
      "Epoch 2, Batch 90, Loss: 0.6542\n",
      "Epoch 2, Train Loss: 0.7481\n",
      "Epoch 2, Validation Loss: 0.7079\n",
      "Precision: 0.0831, Recall: 0.7086, F1 Score: 0.1476, Dice Score: 0.1476, Accuracy: 0.7398\n",
      "Epoch 3, Batch 10, Loss: 0.6974\n",
      "Epoch 3, Batch 20, Loss: 0.5887\n",
      "Epoch 3, Batch 30, Loss: 0.5687\n",
      "Epoch 3, Batch 40, Loss: 0.5045\n",
      "Epoch 3, Batch 50, Loss: 0.5337\n",
      "Epoch 3, Batch 60, Loss: 0.4731\n",
      "Epoch 3, Batch 70, Loss: 0.4715\n",
      "Epoch 3, Batch 80, Loss: 0.4714\n",
      "Epoch 3, Batch 90, Loss: 0.4837\n",
      "Epoch 3, Train Loss: 0.5273\n",
      "Epoch 3, Validation Loss: 0.3833\n",
      "Precision: 0.2721, Recall: 0.8223, F1 Score: 0.4070, Dice Score: 0.4070, Accuracy: 0.9255\n",
      "Epoch 4, Batch 10, Loss: 0.4385\n",
      "Epoch 4, Batch 20, Loss: 0.4136\n",
      "Epoch 4, Batch 30, Loss: 0.4277\n",
      "Epoch 4, Batch 40, Loss: 0.4660\n",
      "Epoch 4, Batch 50, Loss: 0.4419\n",
      "Epoch 4, Batch 60, Loss: 0.4258\n",
      "Epoch 4, Batch 70, Loss: 0.4194\n",
      "Epoch 4, Batch 80, Loss: 0.4130\n",
      "Epoch 4, Batch 90, Loss: 0.4364\n",
      "Epoch 4, Train Loss: 0.4361\n",
      "Epoch 4, Validation Loss: 0.3399\n",
      "Precision: 0.2997, Recall: 0.8359, F1 Score: 0.4400, Dice Score: 0.4400, Accuracy: 0.9343\n",
      "Epoch 5, Batch 10, Loss: 0.3976\n",
      "Epoch 5, Batch 20, Loss: 0.4763\n",
      "Epoch 5, Batch 30, Loss: 0.3961\n",
      "Epoch 5, Batch 40, Loss: 0.3802\n",
      "Epoch 5, Batch 50, Loss: 0.3723\n",
      "Epoch 5, Batch 60, Loss: 0.4051\n",
      "Epoch 5, Batch 70, Loss: 0.3652\n",
      "Epoch 5, Batch 80, Loss: 0.3851\n",
      "Epoch 5, Batch 90, Loss: 0.3897\n",
      "Epoch 5, Train Loss: 0.4017\n",
      "Epoch 5, Validation Loss: 0.3103\n",
      "Precision: 0.3620, Recall: 0.8323, F1 Score: 0.5032, Dice Score: 0.5032, Accuracy: 0.9491\n",
      "Epoch 6, Batch 10, Loss: 0.3663\n",
      "Epoch 6, Batch 20, Loss: 0.3941\n",
      "Epoch 6, Batch 30, Loss: 0.3924\n",
      "Epoch 6, Batch 40, Loss: 0.3519\n",
      "Epoch 6, Batch 50, Loss: 0.3881\n",
      "Epoch 6, Batch 60, Loss: 0.3407\n",
      "Epoch 6, Batch 70, Loss: 0.4074\n",
      "Epoch 6, Batch 80, Loss: 0.4358\n",
      "Epoch 6, Batch 90, Loss: 0.3894\n",
      "Epoch 6, Train Loss: 0.3878\n",
      "Epoch 6, Validation Loss: 0.4007\n",
      "Precision: 0.5392, Recall: 0.6220, F1 Score: 0.5753, Dice Score: 0.5753, Accuracy: 0.9717\n",
      "Epoch 7, Batch 10, Loss: 0.4370\n",
      "Epoch 7, Batch 20, Loss: 0.3451\n",
      "Epoch 7, Batch 30, Loss: 0.3844\n",
      "Epoch 7, Batch 40, Loss: 0.3753\n",
      "Epoch 7, Batch 50, Loss: 0.3530\n",
      "Epoch 7, Batch 60, Loss: 0.3960\n",
      "Epoch 7, Batch 70, Loss: 0.3758\n",
      "Epoch 7, Batch 80, Loss: 0.3712\n",
      "Epoch 7, Batch 90, Loss: 0.3570\n",
      "Epoch 7, Train Loss: 0.3809\n",
      "Epoch 7, Validation Loss: 0.2651\n",
      "Precision: 0.3634, Recall: 0.8529, F1 Score: 0.5090, Dice Score: 0.5090, Accuracy: 0.9492\n",
      "Epoch 8, Batch 10, Loss: 0.3751\n",
      "Epoch 8, Batch 20, Loss: 0.3678\n",
      "Epoch 8, Batch 30, Loss: 0.3493\n",
      "Epoch 8, Batch 40, Loss: 0.3801\n",
      "Epoch 8, Batch 50, Loss: 0.3204\n",
      "Epoch 8, Batch 60, Loss: 0.3103\n",
      "Epoch 8, Batch 70, Loss: 0.3493\n",
      "Epoch 8, Batch 80, Loss: 0.3255\n",
      "Epoch 8, Batch 90, Loss: 0.2930\n",
      "Epoch 8, Train Loss: 0.3402\n",
      "Epoch 8, Validation Loss: 0.2283\n",
      "Precision: 0.4234, Recall: 0.8407, F1 Score: 0.5624, Dice Score: 0.5624, Accuracy: 0.9596\n",
      "Epoch 9, Batch 10, Loss: 0.2766\n",
      "Epoch 9, Batch 20, Loss: 0.3056\n",
      "Epoch 9, Batch 30, Loss: 0.3274\n",
      "Epoch 9, Batch 40, Loss: 0.3515\n",
      "Epoch 9, Batch 50, Loss: 0.3669\n",
      "Epoch 9, Batch 60, Loss: 0.3165\n",
      "Epoch 9, Batch 70, Loss: 0.3479\n",
      "Epoch 9, Batch 80, Loss: 0.3707\n",
      "Epoch 9, Batch 90, Loss: 0.3345\n",
      "Epoch 9, Train Loss: 0.3340\n",
      "Epoch 9, Validation Loss: 0.2239\n",
      "Precision: 0.4034, Recall: 0.8885, F1 Score: 0.5544, Dice Score: 0.5544, Accuracy: 0.9559\n",
      "Epoch 10, Batch 10, Loss: 0.3074\n",
      "Epoch 10, Batch 20, Loss: 0.3678\n",
      "Epoch 10, Batch 30, Loss: 0.3660\n",
      "Epoch 10, Batch 40, Loss: 0.3891\n",
      "Epoch 10, Batch 50, Loss: 0.3382\n",
      "Epoch 10, Batch 60, Loss: 0.2985\n",
      "Epoch 10, Batch 70, Loss: 0.3381\n",
      "Epoch 10, Batch 80, Loss: 0.3487\n",
      "Epoch 10, Batch 90, Loss: 0.2829\n",
      "Epoch 10, Train Loss: 0.3340\n",
      "Epoch 10, Validation Loss: 0.2114\n",
      "Precision: 0.4071, Recall: 0.9002, F1 Score: 0.5602, Dice Score: 0.5602, Accuracy: 0.9563\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dice_score</td><td>▁▂▆▆▇█▇███</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train/loss</td><td>█▇▄▃▂▂▂▁▁▁</td></tr><tr><td>validation/loss</td><td>█▇▃▃▂▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dice_score</td><td>0.56022</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>train/loss</td><td>0.33396</td></tr><tr><td>validation/loss</td><td>0.21138</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fearless-sweep-1</strong> at: <a href='https://wandb.ai/idp2024/fundus-segmentation/runs/awcalll8' target=\"_blank\">https://wandb.ai/idp2024/fundus-segmentation/runs/awcalll8</a><br/> View project at: <a href='https://wandb.ai/idp2024/fundus-segmentation' target=\"_blank\">https://wandb.ai/idp2024/fundus-segmentation</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240701_201258-awcalll8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f733r6x0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: UnetPlusPlus\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdevice: cuda:0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder: resnet152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06278135311710138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: BCE\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tproportion_augmented_data: 0.2\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tim_ivan/idp/wandb/run-20240701_204034-f733r6x0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idp2024/fundus-segmentation/runs/f733r6x0' target=\"_blank\">stilted-sweep-2</a></strong> to <a href='https://wandb.ai/idp2024/fundus-segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/idp2024/fundus-segmentation/sweeps/c7hg8g7l' target=\"_blank\">https://wandb.ai/idp2024/fundus-segmentation/sweeps/c7hg8g7l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idp2024/fundus-segmentation' target=\"_blank\">https://wandb.ai/idp2024/fundus-segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/idp2024/fundus-segmentation/sweeps/c7hg8g7l' target=\"_blank\">https://wandb.ai/idp2024/fundus-segmentation/sweeps/c7hg8g7l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idp2024/fundus-segmentation/runs/f733r6x0' target=\"_blank\">https://wandb.ai/idp2024/fundus-segmentation/runs/f733r6x0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 746, validation set: 60\n",
      "Number of samples in the test set: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss: 0.4020\n",
      "Epoch 1, Batch 20, Loss: 0.2804\n",
      "Epoch 1, Batch 30, Loss: 0.2785\n",
      "Epoch 1, Batch 40, Loss: 0.2841\n",
      "Epoch 1, Batch 50, Loss: 0.2733\n",
      "Epoch 1, Batch 60, Loss: 0.2649\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "from segmentation_util import train_sweep\n",
    "\n",
    "sweep_config = {\n",
    "    'name': 'Fundus-Segmentation-Sweep',\n",
    "    'method': 'bayes',\n",
    "    'parameters': {\n",
    "        'encoder': {\n",
    "            'values': ['resnet152', 'resnext101_32x8d', 'timm-resnest269e', 'timm-regnetx_320', 'timm-regnety_320', 'senet154']\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            \"min\": 0.00001, \n",
    "            \"max\": 0.1\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': 10\n",
    "        },\n",
    "        'loss': {\n",
    "            'values': ['Dice', 'BCE']\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['Adam', 'SGD']\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'value': 8\n",
    "        },\n",
    "        'proportion_augmented_data': {\n",
    "            'values': [0.1, 0.2, 0.3]\n",
    "        },\n",
    "        'architecture': {\n",
    "            'values': ['Unet', 'UnetPlusPlus']\n",
    "        }\n",
    "    },\n",
    "    'metric': {\n",
    "        'name': 'dice_score',\n",
    "        'goal': 'maximize'\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_config['parameters']['device'] = {'value':'cuda:0' if torch.cuda.is_available() else 'cpu'}\n",
    "sweep_id = wandb.sweep(sweep_config, project='fundus-segmentation')\n",
    "wandb.agent(sweep_id, function=train_sweep, count=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
