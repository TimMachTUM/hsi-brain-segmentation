{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net\n",
    "\n",
    "The first approach would be training a U-Net model and use the Encoder as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch\n",
    "! pip install torchvision\n",
    "! pip install pandas\n",
    "! pip install tqdm\n",
    "! pip install matplotlib\n",
    "! pip install psutil\n",
    "! pip install segmentation-models-pytorch\n",
    "! pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtim-mach\u001b[0m (\u001b[33midp2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 540, validation set: 60\n",
      "Number of samples in the test set: 200\n"
     ]
    }
   ],
   "source": [
    "from dataset import SegmentationDataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "from torchvision.transforms import Compose, ToTensor, Grayscale, Normalize\n",
    "\n",
    "\n",
    "train_image_path = './FIVES/train/Original'\n",
    "train_label_path = './FIVES/train/GroundTruth'\n",
    "test_image_path = './FIVES/test/Original'\n",
    "test_label_path = './FIVES/test/GroundTruth'\n",
    "\n",
    "# Define transformations for images\n",
    "image_transform = Compose([\n",
    "    Grayscale(num_output_channels=1),  # Convert image to grayscale\n",
    "    ToTensor()                         # Convert the image to a PyTorch tensor\n",
    "])\n",
    "\n",
    "# Define transformations for labels, if needed\n",
    "label_transform = Compose([\n",
    "    ToTensor()           # Convert label to a tensor\n",
    "])\n",
    "\n",
    "dataset = SegmentationDataset(train_image_path, train_label_path, image_transform, label_transform)\n",
    "testset = SegmentationDataset(test_image_path, test_label_path, image_transform, label_transform)\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_size, val_size = int(0.9 * len(dataset)), int(0.1 * len(dataset))\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "print(f'Number of samples in the training set: {len(train_dataset)}, validation set: {len(val_dataset)}')\n",
    "print(f'Number of samples in the test set: {len(testset)}')\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=8)\n",
    "validationloader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=8)\n",
    "testloader = DataLoader(testset, batch_size=2, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(images, labels, num_images=5):\n",
    "    fig, axs = plt.subplots(nrows=num_images, ncols=2, figsize=(10, num_images * 5))\n",
    "    for i in range(num_images):\n",
    "        img = images[i].numpy().transpose((1, 2, 0))  # Convert from PyTorch tensor format and channel first to channel last\n",
    "        lbl = labels[i].numpy().squeeze()            # Remove extra dimensions\n",
    "        \n",
    "        if num_images == 1:\n",
    "            ax_img = axs[0]\n",
    "            ax_lbl = axs[1]\n",
    "        else:\n",
    "            ax_img = axs[i, 0]\n",
    "            ax_lbl = axs[i, 1]\n",
    "        \n",
    "        ax_img.imshow(img, cmap='gray')\n",
    "        ax_img.set_title('Retina')\n",
    "        ax_img.axis('off')\n",
    "        \n",
    "        ax_lbl.imshow(lbl, cmap='gray')\n",
    "        ax_lbl.set_title('Segmentation Map')\n",
    "        ax_lbl.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(*zip(*[dataset[i] for i in range(5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtim-mach\u001b[0m (\u001b[33midp2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tim_ivan/idp/wandb/run-20240501_155104-9vk3vxtx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idp2024/retina-segmentation/runs/9vk3vxtx' target=\"_blank\">soft-planet-8</a></strong> to <a href='https://wandb.ai/idp2024/retina-segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idp2024/retina-segmentation' target=\"_blank\">https://wandb.ai/idp2024/retina-segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idp2024/retina-segmentation/runs/9vk3vxtx' target=\"_blank\">https://wandb.ai/idp2024/retina-segmentation/runs/9vk3vxtx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss: 0.7835\n",
      "Epoch 1, Batch 20, Loss: 0.6726\n",
      "Epoch 1, Batch 30, Loss: 0.5487\n",
      "Epoch 1, Batch 40, Loss: 0.4015\n",
      "Epoch 1, Batch 50, Loss: 0.3055\n",
      "Epoch 1, Batch 60, Loss: 0.2939\n",
      "Epoch 1, Batch 70, Loss: 0.2013\n",
      "Epoch 1, Batch 80, Loss: 0.2095\n",
      "Epoch 1, Batch 90, Loss: 0.1939\n",
      "Epoch 1, Batch 100, Loss: 0.2136\n",
      "Epoch 1, Batch 110, Loss: 0.1544\n",
      "Epoch 1, Batch 120, Loss: 0.1439\n",
      "Epoch 1, Batch 130, Loss: 0.1583\n",
      "Epoch 1, Batch 140, Loss: 0.1755\n",
      "Epoch 1, Batch 150, Loss: 0.1557\n",
      "Epoch 1, Batch 160, Loss: 0.1570\n",
      "Epoch 1, Batch 170, Loss: 0.1126\n",
      "Epoch 1, Batch 180, Loss: 0.1351\n",
      "Epoch 1, Batch 190, Loss: 0.1240\n",
      "Epoch 1, Batch 200, Loss: 0.1157\n",
      "Epoch 1, Batch 210, Loss: 0.1137\n",
      "Epoch 1, Batch 220, Loss: 0.1478\n",
      "Epoch 1, Batch 230, Loss: 0.1201\n",
      "Epoch 1, Batch 240, Loss: 0.1270\n",
      "Epoch 1, Batch 250, Loss: 0.1319\n",
      "Epoch 1, Batch 260, Loss: 0.1558\n",
      "Epoch 1, Batch 270, Loss: 0.1434\n",
      "Epoch 1, Train Loss: 0.2295\n",
      "Epoch 1, Validation Loss: 0.1679\n",
      "Epoch 2, Batch 10, Loss: 0.1213\n",
      "Epoch 2, Batch 20, Loss: 0.1105\n",
      "Epoch 2, Batch 30, Loss: 0.1256\n",
      "Epoch 2, Batch 40, Loss: 0.1136\n",
      "Epoch 2, Batch 50, Loss: 0.1186\n",
      "Epoch 2, Batch 60, Loss: 0.1168\n",
      "Epoch 2, Batch 70, Loss: 0.1215\n",
      "Epoch 2, Batch 80, Loss: 0.1363\n",
      "Epoch 2, Batch 90, Loss: 0.1172\n",
      "Epoch 2, Batch 100, Loss: 0.1164\n",
      "Epoch 2, Batch 110, Loss: 0.1051\n",
      "Epoch 2, Batch 120, Loss: 0.1018\n",
      "Epoch 2, Batch 130, Loss: 0.1327\n",
      "Epoch 2, Batch 140, Loss: 0.1369\n",
      "Epoch 2, Batch 150, Loss: 0.1045\n",
      "Epoch 2, Batch 160, Loss: 0.0972\n",
      "Epoch 2, Batch 170, Loss: 0.0900\n",
      "Epoch 2, Batch 180, Loss: 0.1663\n",
      "Epoch 2, Batch 190, Loss: 0.1271\n",
      "Epoch 2, Batch 200, Loss: 0.1358\n",
      "Epoch 2, Batch 210, Loss: 0.1159\n",
      "Epoch 2, Batch 220, Loss: 0.1319\n",
      "Epoch 2, Batch 230, Loss: 0.1203\n",
      "Epoch 2, Batch 240, Loss: 0.1074\n",
      "Epoch 2, Batch 250, Loss: 0.1267\n",
      "Epoch 2, Batch 260, Loss: 0.1053\n",
      "Epoch 2, Batch 270, Loss: 0.1547\n",
      "Epoch 2, Train Loss: 0.1206\n",
      "Epoch 2, Validation Loss: 0.1608\n",
      "Epoch 3, Batch 10, Loss: 0.1353\n",
      "Epoch 3, Batch 20, Loss: 0.1240\n",
      "Epoch 3, Batch 30, Loss: 0.1592\n",
      "Epoch 3, Batch 40, Loss: 0.1041\n",
      "Epoch 3, Batch 50, Loss: 0.1002\n",
      "Epoch 3, Batch 60, Loss: 0.1106\n",
      "Epoch 3, Batch 70, Loss: 0.1118\n",
      "Epoch 3, Batch 80, Loss: 0.1101\n",
      "Epoch 3, Batch 90, Loss: 0.1514\n",
      "Epoch 3, Batch 100, Loss: 0.1020\n",
      "Epoch 3, Batch 110, Loss: 0.1049\n",
      "Epoch 3, Batch 120, Loss: 0.1096\n",
      "Epoch 3, Batch 130, Loss: 0.1044\n",
      "Epoch 3, Batch 140, Loss: 0.1075\n",
      "Epoch 3, Batch 150, Loss: 0.0995\n",
      "Epoch 3, Batch 160, Loss: 0.1085\n",
      "Epoch 3, Batch 170, Loss: 0.1051\n",
      "Epoch 3, Batch 180, Loss: 0.0946\n",
      "Epoch 3, Batch 190, Loss: 0.0965\n",
      "Epoch 3, Batch 200, Loss: 0.0915\n",
      "Epoch 3, Batch 210, Loss: 0.0895\n",
      "Epoch 3, Batch 220, Loss: 0.0863\n",
      "Epoch 3, Batch 230, Loss: 0.1005\n",
      "Epoch 3, Batch 240, Loss: 0.1485\n",
      "Epoch 3, Batch 250, Loss: 0.0943\n",
      "Epoch 3, Batch 260, Loss: 0.0941\n",
      "Epoch 3, Batch 270, Loss: 0.1207\n",
      "Epoch 3, Train Loss: 0.1098\n",
      "Epoch 3, Validation Loss: 0.1055\n",
      "Epoch 4, Batch 10, Loss: 0.1025\n",
      "Epoch 4, Batch 20, Loss: 0.1025\n",
      "Epoch 4, Batch 30, Loss: 0.1406\n",
      "Epoch 4, Batch 40, Loss: 0.1078\n",
      "Epoch 4, Batch 50, Loss: 0.1129\n",
      "Epoch 4, Batch 60, Loss: 0.0911\n",
      "Epoch 4, Batch 70, Loss: 0.1092\n",
      "Epoch 4, Batch 80, Loss: 0.1098\n",
      "Epoch 4, Batch 90, Loss: 0.0953\n",
      "Epoch 4, Batch 100, Loss: 0.0908\n",
      "Epoch 4, Batch 110, Loss: 0.0942\n",
      "Epoch 4, Batch 120, Loss: 0.1014\n",
      "Epoch 4, Batch 130, Loss: 0.0987\n",
      "Epoch 4, Batch 140, Loss: 0.0858\n",
      "Epoch 4, Batch 150, Loss: 0.1127\n",
      "Epoch 4, Batch 160, Loss: 0.1253\n",
      "Epoch 4, Batch 170, Loss: 0.1153\n",
      "Epoch 4, Batch 180, Loss: 0.1041\n",
      "Epoch 4, Batch 190, Loss: 0.1372\n",
      "Epoch 4, Batch 200, Loss: 0.0892\n",
      "Epoch 4, Batch 210, Loss: 0.1035\n",
      "Epoch 4, Batch 220, Loss: 0.1123\n",
      "Epoch 4, Batch 230, Loss: 0.0859\n",
      "Epoch 4, Batch 240, Loss: 0.0929\n",
      "Epoch 4, Batch 250, Loss: 0.0894\n",
      "Epoch 4, Batch 260, Loss: 0.0984\n",
      "Epoch 4, Batch 270, Loss: 0.1161\n",
      "Epoch 4, Train Loss: 0.1046\n",
      "Epoch 4, Validation Loss: 0.1248\n",
      "Epoch 5, Batch 10, Loss: 0.0898\n",
      "Epoch 5, Batch 20, Loss: 0.0872\n",
      "Epoch 5, Batch 30, Loss: 0.0890\n",
      "Epoch 5, Batch 40, Loss: 0.0947\n",
      "Epoch 5, Batch 50, Loss: 0.1106\n",
      "Epoch 5, Batch 60, Loss: 0.0873\n",
      "Epoch 5, Batch 70, Loss: 0.0944\n",
      "Epoch 5, Batch 80, Loss: 0.0842\n",
      "Epoch 5, Batch 90, Loss: 0.1129\n",
      "Epoch 5, Batch 100, Loss: 0.1011\n",
      "Epoch 5, Batch 110, Loss: 0.1515\n",
      "Epoch 5, Batch 120, Loss: 0.1051\n",
      "Epoch 5, Batch 130, Loss: 0.0932\n",
      "Epoch 5, Batch 140, Loss: 0.0908\n",
      "Epoch 5, Batch 150, Loss: 0.1164\n",
      "Epoch 5, Batch 160, Loss: 0.0988\n",
      "Epoch 5, Batch 170, Loss: 0.0984\n",
      "Epoch 5, Batch 180, Loss: 0.0800\n",
      "Epoch 5, Batch 190, Loss: 0.1051\n",
      "Epoch 5, Batch 200, Loss: 0.0917\n",
      "Epoch 5, Batch 210, Loss: 0.1071\n",
      "Epoch 5, Batch 220, Loss: 0.1012\n",
      "Epoch 5, Batch 230, Loss: 0.1179\n",
      "Epoch 5, Batch 240, Loss: 0.1138\n",
      "Epoch 5, Batch 250, Loss: 0.1172\n",
      "Epoch 5, Batch 260, Loss: 0.1134\n",
      "Epoch 5, Batch 270, Loss: 0.1148\n",
      "Epoch 5, Train Loss: 0.1025\n",
      "Epoch 5, Validation Loss: 0.1191\n",
      "Epoch 6, Batch 10, Loss: 0.0948\n",
      "Epoch 6, Batch 20, Loss: 0.1155\n",
      "Epoch 6, Batch 30, Loss: 0.1058\n",
      "Epoch 6, Batch 40, Loss: 0.0866\n",
      "Epoch 6, Batch 50, Loss: 0.1142\n",
      "Epoch 6, Batch 60, Loss: 0.0869\n",
      "Epoch 6, Batch 70, Loss: 0.0926\n",
      "Epoch 6, Batch 80, Loss: 0.0962\n",
      "Epoch 6, Batch 90, Loss: 0.1284\n",
      "Epoch 6, Batch 100, Loss: 0.1082\n",
      "Epoch 6, Batch 110, Loss: 0.0911\n",
      "Epoch 6, Batch 120, Loss: 0.0892\n",
      "Epoch 6, Batch 130, Loss: 0.0794\n",
      "Epoch 6, Batch 140, Loss: 0.0966\n",
      "Epoch 6, Batch 150, Loss: 0.1027\n",
      "Epoch 6, Batch 160, Loss: 0.0894\n",
      "Epoch 6, Batch 170, Loss: 0.1086\n",
      "Epoch 6, Batch 180, Loss: 0.1076\n",
      "Epoch 6, Batch 190, Loss: 0.0878\n",
      "Epoch 6, Batch 200, Loss: 0.0980\n",
      "Epoch 6, Batch 210, Loss: 0.0873\n",
      "Epoch 6, Batch 220, Loss: 0.0851\n",
      "Epoch 6, Batch 230, Loss: 0.0945\n",
      "Epoch 6, Batch 240, Loss: 0.0906\n",
      "Epoch 6, Batch 250, Loss: 0.1008\n",
      "Epoch 6, Batch 260, Loss: 0.0934\n",
      "Epoch 6, Batch 270, Loss: 0.0829\n",
      "Epoch 6, Train Loss: 0.0968\n",
      "Epoch 6, Validation Loss: 0.1001\n",
      "Epoch 7, Batch 10, Loss: 0.0875\n",
      "Epoch 7, Batch 20, Loss: 0.1074\n",
      "Epoch 7, Batch 30, Loss: 0.1016\n",
      "Epoch 7, Batch 40, Loss: 0.0823\n",
      "Epoch 7, Batch 50, Loss: 0.0707\n",
      "Epoch 7, Batch 60, Loss: 0.0957\n",
      "Epoch 7, Batch 70, Loss: 0.0898\n",
      "Epoch 7, Batch 80, Loss: 0.1245\n",
      "Epoch 7, Batch 90, Loss: 0.0880\n",
      "Epoch 7, Batch 100, Loss: 0.0871\n",
      "Epoch 7, Batch 110, Loss: 0.0771\n",
      "Epoch 7, Batch 120, Loss: 0.0753\n",
      "Epoch 7, Batch 130, Loss: 0.0680\n",
      "Epoch 7, Batch 140, Loss: 0.0899\n",
      "Epoch 7, Batch 150, Loss: 0.0856\n",
      "Epoch 7, Batch 160, Loss: 0.0838\n",
      "Epoch 7, Batch 170, Loss: 0.0821\n",
      "Epoch 7, Batch 180, Loss: 0.0992\n",
      "Epoch 7, Batch 190, Loss: 0.1113\n",
      "Epoch 7, Batch 200, Loss: 0.0906\n",
      "Epoch 7, Batch 210, Loss: 0.0968\n",
      "Epoch 7, Batch 220, Loss: 0.0993\n",
      "Epoch 7, Batch 230, Loss: 0.0883\n",
      "Epoch 7, Batch 240, Loss: 0.1242\n",
      "Epoch 7, Batch 250, Loss: 0.0965\n",
      "Epoch 7, Batch 260, Loss: 0.0829\n",
      "Epoch 7, Batch 270, Loss: 0.0958\n",
      "Epoch 7, Train Loss: 0.0919\n",
      "Epoch 7, Validation Loss: 0.0988\n",
      "Epoch 8, Batch 10, Loss: 0.0930\n",
      "Epoch 8, Batch 20, Loss: 0.0939\n",
      "Epoch 8, Batch 30, Loss: 0.0768\n",
      "Epoch 8, Batch 40, Loss: 0.0848\n",
      "Epoch 8, Batch 50, Loss: 0.0862\n",
      "Epoch 8, Batch 60, Loss: 0.0917\n",
      "Epoch 8, Batch 70, Loss: 0.0976\n",
      "Epoch 8, Batch 80, Loss: 0.0778\n",
      "Epoch 8, Batch 90, Loss: 0.0976\n",
      "Epoch 8, Batch 100, Loss: 0.0955\n",
      "Epoch 8, Batch 110, Loss: 0.0798\n",
      "Epoch 8, Batch 120, Loss: 0.0831\n",
      "Epoch 8, Batch 130, Loss: 0.0794\n",
      "Epoch 8, Batch 140, Loss: 0.0839\n",
      "Epoch 8, Batch 150, Loss: 0.1017\n",
      "Epoch 8, Batch 160, Loss: 0.0847\n",
      "Epoch 8, Batch 170, Loss: 0.0876\n",
      "Epoch 8, Batch 180, Loss: 0.0978\n",
      "Epoch 8, Batch 190, Loss: 0.1554\n",
      "Epoch 8, Batch 200, Loss: 0.0980\n",
      "Epoch 8, Batch 210, Loss: 0.0965\n",
      "Epoch 8, Batch 220, Loss: 0.0893\n",
      "Epoch 8, Batch 230, Loss: 0.0884\n",
      "Epoch 8, Batch 240, Loss: 0.0793\n",
      "Epoch 8, Batch 250, Loss: 0.0788\n",
      "Epoch 8, Batch 260, Loss: 0.0741\n",
      "Epoch 8, Batch 270, Loss: 0.0862\n",
      "Epoch 8, Train Loss: 0.0903\n",
      "Epoch 8, Validation Loss: 0.0935\n",
      "Epoch 9, Batch 10, Loss: 0.0879\n",
      "Epoch 9, Batch 20, Loss: 0.0845\n",
      "Epoch 9, Batch 30, Loss: 0.0863\n",
      "Epoch 9, Batch 40, Loss: 0.0784\n",
      "Epoch 9, Batch 50, Loss: 0.0862\n",
      "Epoch 9, Batch 60, Loss: 0.0737\n",
      "Epoch 9, Batch 70, Loss: 0.0904\n",
      "Epoch 9, Batch 80, Loss: 0.0820\n",
      "Epoch 9, Batch 90, Loss: 0.0774\n",
      "Epoch 9, Batch 100, Loss: 0.0860\n",
      "Epoch 9, Batch 110, Loss: 0.0784\n",
      "Epoch 9, Batch 120, Loss: 0.0902\n",
      "Epoch 9, Batch 130, Loss: 0.0810\n",
      "Epoch 9, Batch 140, Loss: 0.1344\n",
      "Epoch 9, Batch 150, Loss: 0.0942\n",
      "Epoch 9, Batch 160, Loss: 0.0811\n",
      "Epoch 9, Batch 170, Loss: 0.0735\n",
      "Epoch 9, Batch 180, Loss: 0.0899\n",
      "Epoch 9, Batch 190, Loss: 0.0913\n",
      "Epoch 9, Batch 200, Loss: 0.0958\n",
      "Epoch 9, Batch 210, Loss: 0.1011\n",
      "Epoch 9, Batch 220, Loss: 0.0930\n",
      "Epoch 9, Batch 230, Loss: 0.1041\n",
      "Epoch 9, Batch 240, Loss: 0.0793\n",
      "Epoch 9, Batch 250, Loss: 0.0800\n",
      "Epoch 9, Batch 260, Loss: 0.0764\n",
      "Epoch 9, Batch 270, Loss: 0.0848\n",
      "Epoch 9, Train Loss: 0.0875\n",
      "Epoch 9, Validation Loss: 0.0905\n",
      "Epoch 10, Batch 10, Loss: 0.0723\n",
      "Epoch 10, Batch 20, Loss: 0.0998\n",
      "Epoch 10, Batch 30, Loss: 0.0793\n",
      "Epoch 10, Batch 40, Loss: 0.0734\n",
      "Epoch 10, Batch 50, Loss: 0.1033\n",
      "Epoch 10, Batch 60, Loss: 0.0822\n",
      "Epoch 10, Batch 70, Loss: 0.0785\n",
      "Epoch 10, Batch 80, Loss: 0.1196\n",
      "Epoch 10, Batch 90, Loss: 0.0684\n",
      "Epoch 10, Batch 100, Loss: 0.0727\n",
      "Epoch 10, Batch 110, Loss: 0.0812\n",
      "Epoch 10, Batch 120, Loss: 0.0807\n",
      "Epoch 10, Batch 130, Loss: 0.0885\n",
      "Epoch 10, Batch 140, Loss: 0.0719\n",
      "Epoch 10, Batch 150, Loss: 0.0868\n",
      "Epoch 10, Batch 160, Loss: 0.0874\n",
      "Epoch 10, Batch 170, Loss: 0.0774\n",
      "Epoch 10, Batch 180, Loss: 0.0809\n",
      "Epoch 10, Batch 190, Loss: 0.0871\n",
      "Epoch 10, Batch 200, Loss: 0.0758\n",
      "Epoch 10, Batch 210, Loss: 0.0821\n",
      "Epoch 10, Batch 220, Loss: 0.1038\n",
      "Epoch 10, Batch 230, Loss: 0.1158\n",
      "Epoch 10, Batch 240, Loss: 0.1129\n",
      "Epoch 10, Batch 250, Loss: 0.0980\n",
      "Epoch 10, Batch 260, Loss: 0.1082\n",
      "Epoch 10, Batch 270, Loss: 0.0857\n",
      "Epoch 10, Train Loss: 0.0879\n",
      "Epoch 10, Validation Loss: 0.1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/tim_ivan/idp/util.py\", line 110, in model_pipeline\n",
      "    evaluate_model(model, testloader, device)\n",
      "  File \"/home/tim_ivan/idp/util.py\", line 87, in evaluate_model\n",
      "    print('TP:', tp.item(), 'FP:', fp.item(), 'FN:', fn.item(), 'TN:', tn.item())\n",
      "RuntimeError: a Tensor with 2 elements cannot be converted to Scalar\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>validation/loss</td><td>█▇▂▄▄▂▂▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train/loss</td><td>0.08791</td></tr><tr><td>validation/loss</td><td>0.1129</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">soft-planet-8</strong> at: <a href='https://wandb.ai/idp2024/retina-segmentation/runs/9vk3vxtx' target=\"_blank\">https://wandb.ai/idp2024/retina-segmentation/runs/9vk3vxtx</a><br/> View project at: <a href='https://wandb.ai/idp2024/retina-segmentation' target=\"_blank\">https://wandb.ai/idp2024/retina-segmentation</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240501_155104-9vk3vxtx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 2 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearnnig_rate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     19\u001b[0m criterion \u001b[38;5;241m=\u001b[39m smp\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mDiceLoss(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m model, train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidationloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidationloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretina-segmentation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnet-resnet34-DiceLoss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Plotting the training and validation loss curves\u001b[39;00m\n\u001b[1;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m~/idp/util.py:110\u001b[0m, in \u001b[0;36mmodel_pipeline\u001b[0;34m(model, trainloader, validationloader, testloader, criterion, optimizer, config, project, epochs, model_name, device, batch_print)\u001b[0m\n\u001b[1;32m    108\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    109\u001b[0m train_loss, val_loss \u001b[38;5;241m=\u001b[39m train_and_validate(model, trainloader, validationloader, criterion, optimizer, epochs, model_name, device, batch_print)\n\u001b[0;32m--> 110\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, train_loss, val_loss\n",
      "File \u001b[0;32m~/idp/util.py:87\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, dataloader, device, with_wandb)\u001b[0m\n\u001b[1;32m     85\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     86\u001b[0m tp, fp, fn, tn \u001b[38;5;241m=\u001b[39m smp\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mget_stats(outputs, labels, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP:\u001b[39m\u001b[38;5;124m'\u001b[39m, fp\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN:\u001b[39m\u001b[38;5;124m'\u001b[39m, fn\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTN:\u001b[39m\u001b[38;5;124m'\u001b[39m, tn\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     88\u001b[0m recall \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m smp\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mrecall(tp, fp, fn, tn, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     89\u001b[0m precision \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m smp\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mprecision(tp, fp, fn, tn, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 2 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from util import model_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config = {\n",
    "    'model': 'Unet_resnext50_32x4d_with_DiceLoss',\n",
    "    'learnnig_rate': 0.001,\n",
    "    'epochs': 10,\n",
    "    'batch_size': 2,\n",
    "    'optimizer': 'Adam',\n",
    "    'criterion': 'DiceLoss',\n",
    "}\n",
    "\n",
    "model = smp.Unet('resnext50_32x4d', in_channels=1, classes=1)\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learnnig_rate'])\n",
    "criterion = smp.losses.DiceLoss(mode='binary')\n",
    "\n",
    "model, train_losses, val_losses = model_pipeline(model, trainloader=trainloader, validationloader=validationloader, testloader=testloader, criterion=criterion, optimizer=optimizer,project='retina-segmentation',model_name=config['model'],device=device, config=config)\n",
    "\n",
    "# Plotting the training and validation loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "\n",
    "model = smp.Unet('resnext50_32x4d', in_channels=1, classes=1)\n",
    "model.load_state_dict(torch.load('./models/Unet_resnext50_32x4d_DiceLoss/Unet-resnet34-DiceLoss_epoch10.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9240, Recall: 0.8203, F1 Score: 0.8663, Dice Score: 0.8663, Accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "from util import evaluate_model\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "evaluate_model(model, testloader, device, with_wandb=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
