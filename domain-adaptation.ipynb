{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 534, validation set: 60\n",
      "Number of samples in the test set: 200\n",
      "62 5\n"
     ]
    }
   ],
   "source": [
    "from dataset import (\n",
    "    build_hsi_testloader,\n",
    "    build_hsi_dataloader,\n",
    "    HSIDataset,\n",
    "    build_FIVES_random_crops_dataloaders,\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainloader_source, validationloader_source, testloader_source = (\n",
    "    build_FIVES_random_crops_dataloaders(\n",
    "        batch_size=16,\n",
    "        num_channels=1,\n",
    "        load_from_path='data/FIVES_random_crops_threshold01'\n",
    "    )\n",
    ")\n",
    "\n",
    "window = (500, 600)\n",
    "target_augmented= True\n",
    "trainloader_target = build_hsi_dataloader(\n",
    "    batch_size=8,\n",
    "    train_split=1,\n",
    "    val_split=0,\n",
    "    test_split=0,\n",
    "    window=window,\n",
    "    exclude_labeled_data=True,\n",
    "    augmented=target_augmented,\n",
    "    ring_label_dir='data/helicoid_ring_labels',\n",
    ")[0]\n",
    "\n",
    "testloader_target = build_hsi_testloader(\n",
    "    batch_size=1,\n",
    "    window=window,\n",
    ")\n",
    "\n",
    "print(len(trainloader_target.dataset), len(testloader_target.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Model without Domain Adaptation on Target Testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: nan, Recall: 0.0239, F1 Score: 0.0410, Dice Score: 0.0410, Accuracy: 0.7850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(nan, device='cuda:3'),\n",
       " tensor(0.0239, device='cuda:3'),\n",
       " tensor(0.0410, device='cuda:3'),\n",
       " tensor(0.7850, device='cuda:3'),\n",
       " tensor(0.0410, device='cuda:3'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from segmentation_util import evaluate_model, build_segmentation_model\n",
    "import torch\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = build_segmentation_model('resnet50', 'Unet', device, in_channels=1)\n",
    "\n",
    "evaluate_model(\n",
    "    model, testloader_target, device, with_wandb=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5368, Recall: 0.2351, F1 Score: 0.3072, Dice Score: 0.3072, Accuracy: 0.8104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.5368, device='cuda:3'),\n",
       " tensor(0.2351, device='cuda:3'),\n",
       " tensor(0.3072, device='cuda:3'),\n",
       " tensor(0.8104, device='cuda:3'),\n",
       " tensor(0.3072, device='cuda:3'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from HSI_Net import SegmentationModelWithWindowing\n",
    "from segmentation_util import build_segmentation_model, evaluate_model\n",
    "from ensemble_model import EnsembleModelAverage\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "\n",
    "path = \"./data/helicoid_with_labels\"\n",
    "testset = HSIDataset(path, with_gt=True)\n",
    "testset.crop_dataset()\n",
    "testloader_target = DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "encoder = 'timm-regnetx_320'\n",
    "architecture = 'Linknet'\n",
    "device = ('cuda:5' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "segmenter_single_channel = build_segmentation_model(encoder, architecture, device)\n",
    "segmenter_single_channel.load_state_dict(torch.load('./models/{architecture}-{encoder}-512x512-augmented-with-random-crops-single-channel-focal.pth'.format(architecture=architecture, encoder=encoder)))\n",
    "segmenter_single_channel.eval()\n",
    "\n",
    "window1 = (400, 500)\n",
    "window2 = (500, 600)\n",
    "window3 = (600, 700)\n",
    "window4 = (700, 800)\n",
    "window5 = (800, 900)\n",
    "window6 = (900, 1000)\n",
    "window_full = (400, 1100)\n",
    "\n",
    "\n",
    "model_windowing_400to500 = SegmentationModelWithWindowing(segmenter_single_channel, window=testset.get_window_from_wavelengths(window1))\n",
    "model_with_windowing_500to600 = SegmentationModelWithWindowing(segmenter_single_channel, window=testset.get_window_from_wavelengths(window2))\n",
    "model_windowing_600to700 = SegmentationModelWithWindowing(segmenter_single_channel, window=testset.get_window_from_wavelengths(window3))\n",
    "model_windowing_700to800 = SegmentationModelWithWindowing(segmenter_single_channel, window=testset.get_window_from_wavelengths(window4))\n",
    "model_windowing_800to900 = SegmentationModelWithWindowing(segmenter_single_channel, window=testset.get_window_from_wavelengths(window5))\n",
    "model_windowing_900to1000 = SegmentationModelWithWindowing(segmenter_single_channel, window=testset.get_window_from_wavelengths(window6))\n",
    "model_window_full = SegmentationModelWithWindowing(segmenter_single_channel, window=testset.get_window_from_wavelengths(window_full))\n",
    "\n",
    "model = EnsembleModelAverage([model_windowing_400to500, model_with_windowing_500to600, model_windowing_600to700, model_windowing_700to800, model_windowing_900to1000, model_window_full])\n",
    "evaluate_model(model, testloader_target, device, with_wandb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Adaptation Approaches:\n",
    "### GRL domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtim-mach\u001b[0m (\u001b[33midp2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/home/tim_ivan/idp/wandb/run-20241113_212614-c8spo9w6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idp2024/domain-adaptation/runs/c8spo9w6' target=\"_blank\">GRL-Linknet-timm-regnetx_320-window_500-600-pretrained-random_crops-bloodvessel_ratio01</a></strong> to <a href='https://wandb.ai/idp2024/domain-adaptation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idp2024/domain-adaptation' target=\"_blank\">https://wandb.ai/idp2024/domain-adaptation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idp2024/domain-adaptation/runs/c8spo9w6' target=\"_blank\">https://wandb.ai/idp2024/domain-adaptation/runs/c8spo9w6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from ./models/Linknet-timm-regnetx_320-512x512-augmented-with-random-crops-single-channel-focal.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10/34, Total Loss: 1.8441, Segmentation Loss: 0.4249, Domain Loss Source: 0.6113, Domain Loss Target: 0.6371\n",
      "Epoch 1, Batch 20/34, Total Loss: 1.7106, Segmentation Loss: 0.3447, Domain Loss Source: 0.5976, Domain Loss Target: 0.9083\n",
      "Epoch 1, Batch 30/34, Total Loss: 1.7214, Segmentation Loss: 0.3221, Domain Loss Source: 0.7402, Domain Loss Target: 0.8175\n",
      "Epoch 1, Train Loss: 1.7574\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.9107, Recall: 0.3290, F1 Score: 0.4825, Dice Score: 0.4825, Accuracy: 0.8770\n",
      "Evaluating model performance on target data\n",
      "Precision: nan, Recall: 0.0748, F1 Score: 0.1181, Dice Score: 0.1181, Accuracy: 0.7753\n",
      "Epoch 1, Validation Loss Source: 0.2613, Validation Loss Target: 1.4982\n",
      "Epoch 2, Batch 10/34, Total Loss: 1.8595, Segmentation Loss: 0.2791, Domain Loss Source: 0.7408, Domain Loss Target: 0.9152\n",
      "Epoch 2, Batch 20/34, Total Loss: 1.7727, Segmentation Loss: 0.2733, Domain Loss Source: 0.6027, Domain Loss Target: 0.9855\n",
      "Epoch 2, Batch 30/34, Total Loss: 1.6891, Segmentation Loss: 0.2467, Domain Loss Source: 0.6409, Domain Loss Target: 0.7521\n",
      "Epoch 2, Train Loss: 1.7611\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.9257, Recall: 0.4496, F1 Score: 0.6040, Dice Score: 0.6040, Accuracy: 0.8974\n",
      "Evaluating model performance on target data\n",
      "Precision: nan, Recall: 0.2346, F1 Score: 0.2797, Dice Score: 0.2797, Accuracy: 0.7875\n",
      "Epoch 2, Validation Loss Source: 0.2264, Validation Loss Target: 0.8648\n",
      "Epoch 3, Batch 10/34, Total Loss: 1.6198, Segmentation Loss: 0.2116, Domain Loss Source: 0.6014, Domain Loss Target: 0.7754\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from domain_adaptation_training import model_pipeline\n",
    "\n",
    "encoder = \"timm-regnetx_320\"\n",
    "architecture = \"Linknet\"\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "lambda_param = 0.5\n",
    "learning_rate = 0.001\n",
    "loss = \"BCE\"\n",
    "epochs = 10\n",
    "in_channels = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "config = {\n",
    "    \"model\": \"GRL-{architecture}-{encoder}-window_{window[0]}-{window[1]}-pretrained-random_crops-bloodvessel_ratio01\".format(\n",
    "        architecture=architecture, encoder=encoder, window=window\n",
    "    ),\n",
    "    \"encoder\": encoder,\n",
    "    \"architecture\": architecture,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"lambda_param\": lambda_param,\n",
    "    \"batch_size_source\": trainloader_source.batch_size,\n",
    "    \"batch_size_target\": trainloader_target.batch_size,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"epochs\": epochs,\n",
    "    \"loss\": loss,\n",
    "    \"in_channels\": in_channels,\n",
    "    \"pretrained\": './models/Linknet-timm-regnetx_320-512x512-augmented-with-random-crops-single-channel-focal.pth'\n",
    "}\n",
    "\n",
    "model, train_losses, domain_losses, val_losses_source, val_losses_target = model_pipeline(\n",
    "    trainloader_source,\n",
    "    validationloader_source,\n",
    "    testloader_source,\n",
    "    trainloader_target,\n",
    "    testloader_target,\n",
    "    config,\n",
    "    project=\"domain-adaptation\",\n",
    "    device=device,\n",
    "    batch_print=10,\n",
    "    evaluate=True,\n",
    "    with_overlays=True,\n",
    ")\n",
    "\n",
    "# Plotting the training and validation loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label=\"Combined Training Loss\")\n",
    "plt.plot(domain_losses, label=\"Domain Loss\")\n",
    "plt.plot(val_losses_source, label=\"Validation Loss Source\")\n",
    "plt.plot(val_losses_target, label=\"Validation Loss Target\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Curves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FADA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtim-mach\u001b[0m (\u001b[33midp2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/home/tim_ivan/idp/wandb/run-20250116_140416-mbq1d6g6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idp2024/domain-adaptation/runs/mbq1d6g6' target=\"_blank\">FADA-penalizeRings-CrossEntropy-pretrained-random_crops-bloodvessel_ratio01-3-classes</a></strong> to <a href='https://wandb.ai/idp2024/domain-adaptation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idp2024/domain-adaptation' target=\"_blank\">https://wandb.ai/idp2024/domain-adaptation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idp2024/domain-adaptation/runs/mbq1d6g6' target=\"_blank\">https://wandb.ai/idp2024/domain-adaptation/runs/mbq1d6g6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 534, validation set: 60\n",
      "Number of samples in the test set: 200\n",
      "Loading pretrained model from models/Linknet-timm-regnetx_320-512x512-3-classes.pth\n",
      "Using Gaussian Channel Reduction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:1')\n",
      "torch.Size([7965])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/home/tim_ivan/idp/FADA/train_FADA_unsupervised.py\", line 56, in model_pipeline\n",
      "    return init_model_and_train(\n",
      "  File \"/home/home/tim_ivan/idp/FADA/train_FADA_unsupervised.py\", line 143, in init_model_and_train\n",
      "    train_loss, domain_loss, val_loss_source, val_loss_target = train_and_validate(\n",
      "  File \"/home/home/tim_ivan/idp/FADA/train_FADA_unsupervised.py\", line 239, in train_and_validate\n",
      "    target_domain_data = next(target_domain_iter)\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 348, in __getitem__\n",
      "    return self.datasets[dataset_idx][sample_idx]\n",
      "  File \"/home/home/tim_ivan/idp/dataset.py\", line 211, in __getitem__\n",
      "    hsi_image, label = self.augmentation(hsi_image, label)\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/_container.py\", line 105, in forward\n",
      "    outputs = transform(*inputs)\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/_transform.py\", line 50, in forward\n",
      "    flat_outputs = [\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/_transform.py\", line 51, in <listcomp>\n",
      "    self._transform(inpt, params) if needs_transform else inpt\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/_geometry.py\", line 733, in _transform\n",
      "    return self._call_kernel(\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/_transform.py\", line 35, in _call_kernel\n",
      "    return kernel(inpt, *args, **kwargs)\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/functional/_geometry.py\", line 730, in affine_image\n",
      "    return _apply_grid_transform(image, grid, interpolation.value, fill=fill)\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/functional/_geometry.py\", line 619, in _apply_grid_transform\n",
      "    float_img = grid_sample(float_img, grid, mode=mode, padding_mode=\"zeros\", align_corners=False)\n",
      "  File \"/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/functional.py\", line 4351, in grid_sample\n",
      "    return torch.grid_sampler(input, grid, mode_enum, padding_mode_enum, align_corners)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4428ba1170ac487ab0e61865fc572859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.015 MB of 0.015 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">FADA-penalizeRings-CrossEntropy-pretrained-random_crops-bloodvessel_ratio01-3-classes</strong> at: <a href='https://wandb.ai/idp2024/domain-adaptation/runs/mbq1d6g6' target=\"_blank\">https://wandb.ai/idp2024/domain-adaptation/runs/mbq1d6g6</a><br/> View project at: <a href='https://wandb.ai/idp2024/domain-adaptation' target=\"_blank\">https://wandb.ai/idp2024/domain-adaptation</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250116_140416-mbq1d6g6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFADA-penalizeRings-CrossEntropy-pretrained-random_crops-bloodvessel_ratio01-3-classes\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m: encoder,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mring_label_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/helicoid_ring_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m }\n\u001b[1;32m     34\u001b[0m model, train_losses, domain_losses, val_losses_source, val_losses_target \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mmodel_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdomain-adaptation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_overlays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     47\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombined Training Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/idp/FADA/train_FADA_unsupervised.py:56\u001b[0m, in \u001b[0;36mmodel_pipeline\u001b[0;34m(config, project, device, batch_print, evaluate, with_overlays, save_wandb)\u001b[0m\n\u001b[1;32m     47\u001b[0m config \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m     48\u001b[0m (\n\u001b[1;32m     49\u001b[0m     trainloader_source,\n\u001b[1;32m     50\u001b[0m     validationloader_source,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     testloader_target,\n\u001b[1;32m     54\u001b[0m ) \u001b[38;5;241m=\u001b[39m initialize_data_loaders(config)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_model_and_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainloader_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidationloader_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtestloader_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainloader_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtestloader_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_print\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_overlays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_wandb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/idp/FADA/train_FADA_unsupervised.py:143\u001b[0m, in \u001b[0;36minit_model_and_train\u001b[0;34m(trainloader_source, validationloader_source, testloader_source, trainloader_target, testloader_target, config, device, batch_print, evaluate, with_overlays, save_wandb)\u001b[0m\n\u001b[1;32m    138\u001b[0m with_contrastive_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontrastive_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mcontrastive_loss\n\u001b[1;32m    139\u001b[0m penalize_rings_weight \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    140\u001b[0m     config\u001b[38;5;241m.\u001b[39mpenalize_rings_weight \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpenalize_rings_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m    141\u001b[0m )\n\u001b[0;32m--> 143\u001b[0m train_loss, domain_loss, val_loss_source, val_loss_target \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainloader_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidationloader_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtestloader_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainloader_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtestloader_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion_segmentation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_fea\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_dis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_print\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_overlays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_overlays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhsi_reducer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreducer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_wandb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_contrastive_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_contrastive_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpenalize_rings_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalize_rings_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel:\n",
      "File \u001b[0;32m~/idp/FADA/train_FADA_unsupervised.py:239\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(feature_extractor, classifier, discriminator, trainloader_source, validationloader_source, testloader_source, trainloader_target, testloader_target, criterion_segmentation, optimizer_fea, optimizer_cls, optimizer_D, epochs, model_name, device, batch_print, with_overlays, hsi_reducer, save_wandb, with_contrastive_loss, penalize_rings_weight)\u001b[0m\n\u001b[1;32m    234\u001b[0m src_input, src_label \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    235\u001b[0m     seg_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m    236\u001b[0m     seg_data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[1;32m    237\u001b[0m )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Get target domain data for the current window\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m target_domain_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget_domain_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m tgt_input \u001b[38;5;241m=\u001b[39m target_domain_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    242\u001b[0m src_size \u001b[38;5;241m=\u001b[39m src_input\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torch/utils/data/dataset.py:348\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/idp/dataset.py:211\u001b[0m, in \u001b[0;36mHSIDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    208\u001b[0m hsi_image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(hsi_image, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmentation:\n\u001b[0;32m--> 211\u001b[0m     hsi_image, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhsi_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_transform \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_transform:\n\u001b[1;32m    214\u001b[0m     hsi_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_transform(hsi_image)\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/_container.py:105\u001b[0m, in \u001b[0;36mRandomApply.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m--> 105\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/_transform.py:50\u001b[0m, in \u001b[0;36mTransform.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     45\u001b[0m needs_transform_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_transform_list(flat_inputs)\n\u001b[1;32m     46\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params(\n\u001b[1;32m     47\u001b[0m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m flat_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(inpt, params) \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[1;32m     53\u001b[0m ]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/_transform.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m needs_transform_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_transform_list(flat_inputs)\n\u001b[1;32m     46\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params(\n\u001b[1;32m     47\u001b[0m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     50\u001b[0m flat_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[1;32m     53\u001b[0m ]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/_geometry.py:733\u001b[0m, in \u001b[0;36mRandomAffine._transform\u001b[0;34m(self, inpt, params)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, inpt: Any, params: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    732\u001b[0m     fill \u001b[38;5;241m=\u001b[39m _get_fill(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fill, \u001b[38;5;28mtype\u001b[39m(inpt))\n\u001b[0;32m--> 733\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_kernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/_transform.py:35\u001b[0m, in \u001b[0;36mTransform._call_kernel\u001b[0;34m(self, functional, inpt, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_kernel\u001b[39m(\u001b[38;5;28mself\u001b[39m, functional: Callable, inpt: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     34\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m _get_kernel(functional, \u001b[38;5;28mtype\u001b[39m(inpt), allow_passthrough\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/functional/_geometry.py:730\u001b[0m, in \u001b[0;36maffine_image\u001b[0;34m(image, angle, translate, scale, shear, interpolation, fill, center)\u001b[0m\n\u001b[1;32m    728\u001b[0m theta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(matrix, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    729\u001b[0m grid \u001b[38;5;241m=\u001b[39m _affine_grid(theta, w\u001b[38;5;241m=\u001b[39mwidth, h\u001b[38;5;241m=\u001b[39mheight, ow\u001b[38;5;241m=\u001b[39mwidth, oh\u001b[38;5;241m=\u001b[39mheight)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_grid_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torchvision/transforms/v2/functional/_geometry.py:619\u001b[0m, in \u001b[0;36m_apply_grid_transform\u001b[0;34m(img, grid, mode, fill)\u001b[0m\n\u001b[1;32m    614\u001b[0m     mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\n\u001b[1;32m    615\u001b[0m         (squashed_batch_size, \u001b[38;5;241m1\u001b[39m, input_height, input_width), dtype\u001b[38;5;241m=\u001b[39mfloat_img\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mfloat_img\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    616\u001b[0m     )\n\u001b[1;32m    617\u001b[0m     float_img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((float_img, mask), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 619\u001b[0m float_img \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfloat_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzeros\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# Fill with required color\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fill \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/idp/.venv/lib/python3.8/site-packages/torch/nn/functional.py:4351\u001b[0m, in \u001b[0;36mgrid_sample\u001b[0;34m(input, grid, mode, padding_mode, align_corners)\u001b[0m\n\u001b[1;32m   4343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   4344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault grid_sample and affine_grid behavior has changed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto align_corners=False since 1.3.0. Please specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4346\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malign_corners=True if the old behavior is desired. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee the documentation of grid_sample for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4348\u001b[0m     )\n\u001b[1;32m   4349\u001b[0m     align_corners \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from FADA.train_FADA_unsupervised import model_pipeline\n",
    "import torch\n",
    "\n",
    "encoder = \"timm-regnetx_320\"\n",
    "architecture = \"Linknet\"\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = {\n",
    "    \"model\": \"FADA-penalizeRings-CrossEntropy-pretrained-random_crops-bloodvessel_ratio01-3-classes\",\n",
    "    \"encoder\": encoder,\n",
    "    \"architecture\": architecture,\n",
    "    \"in_channels\": 3,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"batch_size_source\": 16,\n",
    "    \"batch_size_target\": 1,\n",
    "    \"learning_rate_fea\": 0.001862602441467392,\n",
    "    \"learning_rate_cls\": 0.007213533657259828,\n",
    "    \"learning_rate_dis\": 0.00014998936792878458,\n",
    "    \"ndf\": 512,\n",
    "    \"epochs\": 10,\n",
    "    \"seg_loss\": \"CrossEntropy\",\n",
    "    \"pretrained\": \"models/Linknet-timm-regnetx_320-512x512-3-classes.pth\",\n",
    "    \"augmented\": True,\n",
    "    \"contrastive_loss\": True,\n",
    "    \"penalize_rings_weight\": 1,\n",
    "    \"classes\": 3,\n",
    "    \"gaussian\": \"models/gcr_comic-sweep.pth\",\n",
    "    \"dataset_path\": \"./data/FIVES_random_crops_threshold01\",\n",
    "    \"ring_label_dir\": \"data/helicoid_ring_labels\",\n",
    "}\n",
    "\n",
    "\n",
    "model, train_losses, domain_losses, val_losses_source, val_losses_target = (\n",
    "    model_pipeline(\n",
    "        config,\n",
    "        project=\"domain-adaptation\",\n",
    "        device=device,\n",
    "        batch_print=5,\n",
    "        evaluate=True,\n",
    "        with_overlays=True,\n",
    "        save_wandb=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label=\"Combined Training Loss\")\n",
    "plt.plot(domain_losses, label=\"Domain Loss\")\n",
    "plt.plot(val_losses_source, label=\"Validation Loss Source\")\n",
    "plt.plot(val_losses_target, label=\"Validation Loss Target\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Curves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Domain Adapatation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtim-mach\u001b[0m (\u001b[33midp2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/home/tim_ivan/idp/wandb/run-20241113_231515-g7k8n98v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idp2024/supervised-domain-adaptation/runs/g7k8n98v' target=\"_blank\">GRL-Linknet-timm-regnetx_320-window_500-600-pretrained-random_crops-bloodvessel_ratio01-supervised</a></strong> to <a href='https://wandb.ai/idp2024/supervised-domain-adaptation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idp2024/supervised-domain-adaptation' target=\"_blank\">https://wandb.ai/idp2024/supervised-domain-adaptation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idp2024/supervised-domain-adaptation/runs/g7k8n98v' target=\"_blank\">https://wandb.ai/idp2024/supervised-domain-adaptation/runs/g7k8n98v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from ./models/Linknet-timm-regnetx_320-512x512-augmented-with-random-crops-single-channel-focal.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1/34, Total Loss: 2.1479, Segmentation Loss: 0.7283, Domain Loss Source: 0.7582, Domain Loss Target: 0.6614\n",
      "Epoch 1, Batch 2/34, Total Loss: 30.4464, Segmentation Loss: 0.6874, Domain Loss Source: 0.0000, Domain Loss Target: 29.7590\n",
      "Epoch 1, Batch 3/34, Total Loss: 45.6899, Segmentation Loss: 0.6732, Domain Loss Source: 43.6820, Domain Loss Target: 1.3348\n",
      "Epoch 1, Batch 4/34, Total Loss: 60.7336, Segmentation Loss: 0.6997, Domain Loss Source: 58.5175, Domain Loss Target: 1.5164\n",
      "Epoch 1, Batch 5/34, Total Loss: 19.6700, Segmentation Loss: 0.6691, Domain Loss Source: 15.5772, Domain Loss Target: 3.4236\n",
      "Epoch 1, Batch 6/34, Total Loss: 23.4743, Segmentation Loss: 0.7398, Domain Loss Source: 16.1773, Domain Loss Target: 6.5572\n",
      "Epoch 1, Batch 7/34, Total Loss: 39.3069, Segmentation Loss: 0.6454, Domain Loss Source: 0.7192, Domain Loss Target: 37.9422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 8/34, Total Loss: 31.2116, Segmentation Loss: 0.7010, Domain Loss Source: 11.5278, Domain Loss Target: 18.9828\n",
      "Epoch 1, Batch 9/34, Total Loss: 6.9516, Segmentation Loss: 0.6254, Domain Loss Source: 5.3976, Domain Loss Target: 0.9286\n",
      "Epoch 1, Batch 10/34, Total Loss: 3.5846, Segmentation Loss: 0.6483, Domain Loss Source: 0.1458, Domain Loss Target: 2.7905\n",
      "Epoch 1, Batch 11/34, Total Loss: 10.3006, Segmentation Loss: 0.6348, Domain Loss Source: 2.2692, Domain Loss Target: 7.3966\n",
      "Epoch 1, Batch 12/34, Total Loss: 9.2024, Segmentation Loss: 0.6809, Domain Loss Source: 1.9968, Domain Loss Target: 6.5247\n",
      "Epoch 1, Batch 13/34, Total Loss: 4.0135, Segmentation Loss: 0.6346, Domain Loss Source: 3.1238, Domain Loss Target: 0.2550\n",
      "Epoch 1, Batch 14/34, Total Loss: 19.5268, Segmentation Loss: 0.6613, Domain Loss Source: 6.5280, Domain Loss Target: 12.3374\n",
      "Epoch 1, Batch 15/34, Total Loss: 2.5017, Segmentation Loss: 0.6154, Domain Loss Source: 1.8577, Domain Loss Target: 0.0286\n",
      "Epoch 1, Batch 16/34, Total Loss: 6.2783, Segmentation Loss: 0.7047, Domain Loss Source: 5.0740, Domain Loss Target: 0.4996\n",
      "Epoch 1, Batch 17/34, Total Loss: 1.7260, Segmentation Loss: 0.5996, Domain Loss Source: 0.6674, Domain Loss Target: 0.4590\n",
      "Epoch 1, Batch 18/34, Total Loss: 5.5996, Segmentation Loss: 0.5644, Domain Loss Source: 0.0086, Domain Loss Target: 5.0266\n",
      "Epoch 1, Batch 19/34, Total Loss: 10.5274, Segmentation Loss: 0.6068, Domain Loss Source: 6.8193, Domain Loss Target: 3.1014\n",
      "Epoch 1, Batch 20/34, Total Loss: 10.7684, Segmentation Loss: 0.6359, Domain Loss Source: 0.4011, Domain Loss Target: 9.7314\n",
      "Epoch 1, Batch 21/34, Total Loss: 1.3909, Segmentation Loss: 0.5996, Domain Loss Source: 0.7165, Domain Loss Target: 0.0748\n",
      "Epoch 1, Batch 22/34, Total Loss: 11.5365, Segmentation Loss: 0.6705, Domain Loss Source: 8.4255, Domain Loss Target: 2.4406\n",
      "Epoch 1, Batch 23/34, Total Loss: 3.7295, Segmentation Loss: 0.6413, Domain Loss Source: 3.0493, Domain Loss Target: 0.0388\n",
      "Epoch 1, Batch 24/34, Total Loss: 5.4131, Segmentation Loss: 0.6529, Domain Loss Source: 4.6816, Domain Loss Target: 0.0786\n",
      "Epoch 1, Batch 25/34, Total Loss: 2.5026, Segmentation Loss: 0.6071, Domain Loss Source: 1.8850, Domain Loss Target: 0.0105\n",
      "Epoch 1, Batch 26/34, Total Loss: 3.0495, Segmentation Loss: 0.5626, Domain Loss Source: 0.2849, Domain Loss Target: 2.2021\n",
      "Epoch 1, Batch 27/34, Total Loss: 4.2334, Segmentation Loss: 0.6126, Domain Loss Source: 1.0855, Domain Loss Target: 2.5353\n",
      "Epoch 1, Batch 28/34, Total Loss: 5.0916, Segmentation Loss: 0.5697, Domain Loss Source: 0.0062, Domain Loss Target: 4.5157\n",
      "Epoch 1, Batch 29/34, Total Loss: 1.8426, Segmentation Loss: 0.5427, Domain Loss Source: 0.0003, Domain Loss Target: 1.2996\n",
      "Epoch 1, Batch 30/34, Total Loss: 3.1234, Segmentation Loss: 0.5734, Domain Loss Source: 1.2844, Domain Loss Target: 1.2656\n",
      "Epoch 1, Batch 31/34, Total Loss: 2.0092, Segmentation Loss: 0.5704, Domain Loss Source: 0.1472, Domain Loss Target: 1.2916\n",
      "Epoch 1, Batch 32/34, Total Loss: 4.5006, Segmentation Loss: 0.5560, Domain Loss Source: 0.3734, Domain Loss Target: 3.5712\n",
      "Epoch 1, Batch 33/34, Total Loss: 4.0462, Segmentation Loss: 0.5730, Domain Loss Source: 3.4730, Domain Loss Target: 0.0002\n",
      "Epoch 1, Batch 34/34, Total Loss: 4.0458, Segmentation Loss: 0.5671, Domain Loss Source: 3.4323, Domain Loss Target: 0.0463\n",
      "Epoch 1, Train Loss: 11.7699\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.7823, Recall: 0.4425, F1 Score: 0.5616, Dice Score: 0.5616, Accuracy: 0.8803\n",
      "Evaluating model performance on target data\n",
      "Precision: nan, Recall: 0.1608, F1 Score: 0.1985, Dice Score: 0.1985, Accuracy: 0.7622\n",
      "Epoch 1, Validation Loss Source: 0.4782, Validation Loss Target: 0.8067\n",
      "Epoch 2, Batch 1/34, Total Loss: 2.9017, Segmentation Loss: 0.5977, Domain Loss Source: 2.2515, Domain Loss Target: 0.0524\n",
      "Epoch 2, Batch 2/34, Total Loss: 4.8484, Segmentation Loss: 0.5466, Domain Loss Source: 3.2542, Domain Loss Target: 1.0476\n",
      "Epoch 2, Batch 3/34, Total Loss: 0.5970, Segmentation Loss: 0.5481, Domain Loss Source: 0.0028, Domain Loss Target: 0.0461\n",
      "Epoch 2, Batch 4/34, Total Loss: 2.6450, Segmentation Loss: 0.5633, Domain Loss Source: 0.0003, Domain Loss Target: 2.0815\n",
      "Epoch 2, Batch 5/34, Total Loss: 4.1850, Segmentation Loss: 0.5813, Domain Loss Source: 0.0355, Domain Loss Target: 3.5682\n",
      "Epoch 2, Batch 6/34, Total Loss: 3.6665, Segmentation Loss: 0.5624, Domain Loss Source: 0.4885, Domain Loss Target: 2.6156\n",
      "Epoch 2, Batch 7/34, Total Loss: 0.9493, Segmentation Loss: 0.5857, Domain Loss Source: 0.0459, Domain Loss Target: 0.3177\n",
      "Epoch 2, Batch 8/34, Total Loss: 1.8488, Segmentation Loss: 0.5683, Domain Loss Source: 0.7101, Domain Loss Target: 0.5705\n",
      "Epoch 2, Batch 9/34, Total Loss: 1.1248, Segmentation Loss: 0.5281, Domain Loss Source: 0.5456, Domain Loss Target: 0.0512\n",
      "Epoch 2, Batch 10/34, Total Loss: 2.2108, Segmentation Loss: 0.5632, Domain Loss Source: 1.5653, Domain Loss Target: 0.0823\n",
      "Epoch 2, Batch 11/34, Total Loss: 3.0093, Segmentation Loss: 0.5071, Domain Loss Source: 2.5005, Domain Loss Target: 0.0016\n",
      "Epoch 2, Batch 12/34, Total Loss: 1.4516, Segmentation Loss: 0.5773, Domain Loss Source: 0.8741, Domain Loss Target: 0.0001\n",
      "Epoch 2, Batch 13/34, Total Loss: 0.8983, Segmentation Loss: 0.5071, Domain Loss Source: 0.3265, Domain Loss Target: 0.0646\n",
      "Epoch 2, Batch 14/34, Total Loss: 0.8333, Segmentation Loss: 0.5565, Domain Loss Source: 0.0016, Domain Loss Target: 0.2752\n",
      "Epoch 2, Batch 15/34, Total Loss: 0.6979, Segmentation Loss: 0.5208, Domain Loss Source: 0.0072, Domain Loss Target: 0.1699\n",
      "Epoch 2, Batch 16/34, Total Loss: 2.1657, Segmentation Loss: 0.5887, Domain Loss Source: 0.0449, Domain Loss Target: 1.5321\n",
      "Epoch 2, Batch 17/34, Total Loss: 1.7429, Segmentation Loss: 0.4979, Domain Loss Source: 0.0018, Domain Loss Target: 1.2432\n",
      "Epoch 2, Batch 18/34, Total Loss: 1.9530, Segmentation Loss: 0.4572, Domain Loss Source: 0.2773, Domain Loss Target: 1.2186\n",
      "Epoch 2, Batch 19/34, Total Loss: 0.9406, Segmentation Loss: 0.4863, Domain Loss Source: 0.4377, Domain Loss Target: 0.0166\n",
      "Epoch 2, Batch 20/34, Total Loss: 1.6731, Segmentation Loss: 0.4916, Domain Loss Source: 1.1809, Domain Loss Target: 0.0006\n",
      "Epoch 2, Batch 21/34, Total Loss: 1.0084, Segmentation Loss: 0.5002, Domain Loss Source: 0.4919, Domain Loss Target: 0.0163\n",
      "Epoch 2, Batch 22/34, Total Loss: 2.8156, Segmentation Loss: 0.6112, Domain Loss Source: 1.9937, Domain Loss Target: 0.2107\n",
      "Epoch 2, Batch 23/34, Total Loss: 0.6283, Segmentation Loss: 0.5690, Domain Loss Source: 0.0467, Domain Loss Target: 0.0126\n",
      "Epoch 2, Batch 24/34, Total Loss: 1.6291, Segmentation Loss: 0.5829, Domain Loss Source: 0.9306, Domain Loss Target: 0.1156\n",
      "Epoch 2, Batch 25/34, Total Loss: 0.7569, Segmentation Loss: 0.4917, Domain Loss Source: 0.0356, Domain Loss Target: 0.2296\n",
      "Epoch 2, Batch 26/34, Total Loss: 1.4479, Segmentation Loss: 0.4954, Domain Loss Source: 0.0498, Domain Loss Target: 0.9027\n",
      "Epoch 2, Batch 27/34, Total Loss: 1.9658, Segmentation Loss: 0.5060, Domain Loss Source: 1.3640, Domain Loss Target: 0.0958\n",
      "Epoch 2, Batch 28/34, Total Loss: 1.0930, Segmentation Loss: 0.4625, Domain Loss Source: 0.1319, Domain Loss Target: 0.4986\n",
      "Epoch 2, Batch 29/34, Total Loss: 1.4581, Segmentation Loss: 0.4607, Domain Loss Source: 0.0120, Domain Loss Target: 0.9854\n",
      "Epoch 2, Batch 30/34, Total Loss: 1.0058, Segmentation Loss: 0.4967, Domain Loss Source: 0.0293, Domain Loss Target: 0.4798\n",
      "Epoch 2, Batch 31/34, Total Loss: 0.9356, Segmentation Loss: 0.4562, Domain Loss Source: 0.4568, Domain Loss Target: 0.0227\n",
      "Epoch 2, Batch 32/34, Total Loss: 0.7004, Segmentation Loss: 0.4840, Domain Loss Source: 0.1978, Domain Loss Target: 0.0186\n",
      "Epoch 2, Batch 33/34, Total Loss: 1.2428, Segmentation Loss: 0.4708, Domain Loss Source: 0.7382, Domain Loss Target: 0.0338\n",
      "Epoch 2, Batch 34/34, Total Loss: 0.8910, Segmentation Loss: 0.4652, Domain Loss Source: 0.2035, Domain Loss Target: 0.2223\n",
      "Epoch 2, Train Loss: 1.7036\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from supervised_domain_adaptation import model_pipeline\n",
    "\n",
    "trainloader_target_labeled = DataLoader(\n",
    "    Subset(testset, [0]),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "testloader_target = DataLoader(\n",
    "    Subset(testset, [1, 2, 3, 4]), batch_size=1, shuffle=False\n",
    ")\n",
    "\n",
    "encoder = \"timm-regnetx_320\"\n",
    "architecture = \"Linknet\"\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "lambda_param = 0.5\n",
    "learning_rate = 0.001\n",
    "loss = \"Dice\"\n",
    "epochs = 10\n",
    "in_channels = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "config = {\n",
    "    \"model\": \"GRL-{architecture}-{encoder}-window_{window[0]}-{window[1]}-pretrained-random_crops-bloodvessel_ratio01-supervised\".format(\n",
    "        architecture=architecture, encoder=encoder, window=window\n",
    "    ),\n",
    "    \"encoder\": encoder,\n",
    "    \"architecture\": architecture,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"lambda_param\": lambda_param,\n",
    "    \"batch_size_source\": trainloader_source.batch_size,\n",
    "    \"batch_size_target\": trainloader_target.batch_size,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"epochs\": epochs,\n",
    "    \"loss\": loss,\n",
    "    \"in_channels\": in_channels,\n",
    "    \"pretrained\": './models/Linknet-timm-regnetx_320-512x512-augmented-with-random-crops-single-channel-focal.pth',\n",
    "    \"supervised\": True,\n",
    "}\n",
    "\n",
    "model, train_losses, domain_losses, val_losses_source, val_losses_target = model_pipeline(\n",
    "    trainloader_source,\n",
    "    validationloader_source,\n",
    "    testloader_source,\n",
    "    trainloader_target_labeled,\n",
    "    trainloader_target,\n",
    "    testloader_target,\n",
    "    config,\n",
    "    project=\"supervised-domain-adaptation\",\n",
    "    device=device,\n",
    "    batch_print=1,\n",
    "    evaluate=True,\n",
    "    with_overlays=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtim-mach\u001b[0m (\u001b[33midp2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/home/tim_ivan/idp/wandb/run-20241113_215941-qd45bcaj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idp2024/supervised-domain-adaptation/runs/qd45bcaj' target=\"_blank\">FADA-Linknet-timm-regnetx_320-window_500-600_pretrained-augmented_target-random_crops_bloodvessel_ratio01</a></strong> to <a href='https://wandb.ai/idp2024/supervised-domain-adaptation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idp2024/supervised-domain-adaptation' target=\"_blank\">https://wandb.ai/idp2024/supervised-domain-adaptation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idp2024/supervised-domain-adaptation/runs/qd45bcaj' target=\"_blank\">https://wandb.ai/idp2024/supervised-domain-adaptation/runs/qd45bcaj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from ./models/Linknet-timm-regnetx_320-512x512-augmented-with-random-crops-single-channel-focal.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10/34, Total Loss: 1.0578, Segmentation Loss: 0.4373, Domain Loss Source: 0.3387, Domain Loss Target: 0.2318, Adversarial Loss Target: 0.0009\n",
      "Epoch 1, Batch 20/34, Total Loss: 0.9842, Segmentation Loss: 0.3694, Domain Loss Source: 0.3450, Domain Loss Target: 0.2909, Adversarial Loss Target: 0.0012\n",
      "Epoch 1, Batch 30/34, Total Loss: 0.8321, Segmentation Loss: 0.3126, Domain Loss Source: 0.2059, Domain Loss Target: 0.2563, Adversarial Loss Target: 0.0010\n",
      "Epoch 1, Train Loss: 4.9357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model performance on source data\n",
      "Precision: 0.9679, Recall: 0.2987, F1 Score: 0.4549, Dice Score: 0.4549, Accuracy: 0.8754\n",
      "Evaluating model performance on target data\n",
      "Precision: nan, Recall: 0.1847, F1 Score: 0.2401, Dice Score: 0.2401, Accuracy: 0.7989\n",
      "Epoch 1, Validation Loss Source: 0.2642, Validation Loss Target: 0.6929\n",
      "Epoch 2, Batch 10/34, Total Loss: 0.7133, Segmentation Loss: 0.2836, Domain Loss Source: 0.2742, Domain Loss Target: 0.1458, Adversarial Loss Target: 0.0018\n",
      "Epoch 2, Batch 20/34, Total Loss: 0.7254, Segmentation Loss: 0.2543, Domain Loss Source: 0.2818, Domain Loss Target: 0.1544, Adversarial Loss Target: 0.0020\n",
      "Epoch 2, Batch 30/34, Total Loss: 0.6715, Segmentation Loss: 0.2273, Domain Loss Source: 0.3369, Domain Loss Target: 0.1476, Adversarial Loss Target: 0.0018\n",
      "Epoch 2, Train Loss: 3.5858\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.9597, Recall: 0.4010, F1 Score: 0.5633, Dice Score: 0.5633, Accuracy: 0.8920\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.4168, Recall: 0.2992, F1 Score: 0.3436, Dice Score: 0.3436, Accuracy: 0.8037\n",
      "Epoch 2, Validation Loss Source: 0.2848, Validation Loss Target: 0.5648\n",
      "Epoch 3, Batch 10/34, Total Loss: 0.6636, Segmentation Loss: 0.2251, Domain Loss Source: 0.4584, Domain Loss Target: 0.0825, Adversarial Loss Target: 0.0027\n",
      "Epoch 3, Batch 20/34, Total Loss: 0.7144, Segmentation Loss: 0.2106, Domain Loss Source: 0.2956, Domain Loss Target: 0.1851, Adversarial Loss Target: 0.0014\n",
      "Epoch 3, Batch 30/34, Total Loss: 0.6797, Segmentation Loss: 0.1863, Domain Loss Source: 0.2117, Domain Loss Target: 0.2501, Adversarial Loss Target: 0.0012\n",
      "Epoch 3, Train Loss: 3.5167\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.9353, Recall: 0.4632, F1 Score: 0.6165, Dice Score: 0.6165, Accuracy: 0.9003\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.5283, Recall: 0.6093, F1 Score: 0.5611, Dice Score: 0.5611, Accuracy: 0.8273\n",
      "Epoch 3, Validation Loss Source: 0.2840, Validation Loss Target: 0.4886\n",
      "Epoch 4, Batch 10/34, Total Loss: 0.6459, Segmentation Loss: 0.1984, Domain Loss Source: 0.4003, Domain Loss Target: 0.1105, Adversarial Loss Target: 0.0021\n",
      "Epoch 4, Batch 20/34, Total Loss: 0.6293, Segmentation Loss: 0.1863, Domain Loss Source: 0.2560, Domain Loss Target: 0.1736, Adversarial Loss Target: 0.0015\n",
      "Epoch 4, Batch 30/34, Total Loss: 0.6457, Segmentation Loss: 0.1615, Domain Loss Source: 0.1470, Domain Loss Target: 0.3052, Adversarial Loss Target: 0.0007\n",
      "Epoch 4, Train Loss: 3.2743\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.9285, Recall: 0.4940, F1 Score: 0.6417, Dice Score: 0.6417, Accuracy: 0.9046\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.5303, Recall: 0.6397, F1 Score: 0.5764, Dice Score: 0.5764, Accuracy: 0.8227\n",
      "Epoch 4, Validation Loss Source: 0.2813, Validation Loss Target: 0.5494\n",
      "Epoch 5, Batch 10/34, Total Loss: 0.6443, Segmentation Loss: 0.1813, Domain Loss Source: 0.4674, Domain Loss Target: 0.0726, Adversarial Loss Target: 0.0023\n",
      "Epoch 5, Batch 20/34, Total Loss: 0.6633, Segmentation Loss: 0.1701, Domain Loss Source: 0.2598, Domain Loss Target: 0.2123, Adversarial Loss Target: 0.0011\n",
      "Epoch 5, Batch 30/34, Total Loss: 0.6203, Segmentation Loss: 0.1447, Domain Loss Source: 0.2218, Domain Loss Target: 0.1649, Adversarial Loss Target: 0.0015\n",
      "Epoch 5, Train Loss: 3.2961\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.9116, Recall: 0.5073, F1 Score: 0.6480, Dice Score: 0.6480, Accuracy: 0.9048\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.5202, Recall: 0.7135, F1 Score: 0.5937, Dice Score: 0.5937, Accuracy: 0.8105\n",
      "Epoch 5, Validation Loss Source: 0.2856, Validation Loss Target: 0.6232\n",
      "Epoch 6, Batch 10/34, Total Loss: 0.5921, Segmentation Loss: 0.1666, Domain Loss Source: 0.1738, Domain Loss Target: 0.2082, Adversarial Loss Target: 0.0011\n",
      "Epoch 6, Batch 20/34, Total Loss: 0.5750, Segmentation Loss: 0.1585, Domain Loss Source: 0.1904, Domain Loss Target: 0.2018, Adversarial Loss Target: 0.0021\n",
      "Epoch 6, Batch 30/34, Total Loss: 0.5659, Segmentation Loss: 0.1321, Domain Loss Source: 0.2841, Domain Loss Target: 0.1192, Adversarial Loss Target: 0.0017\n",
      "Epoch 6, Train Loss: 3.0074\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.9043, Recall: 0.5117, F1 Score: 0.6495, Dice Score: 0.6495, Accuracy: 0.9046\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.5185, Recall: 0.7163, F1 Score: 0.5894, Dice Score: 0.5894, Accuracy: 0.8060\n",
      "Epoch 6, Validation Loss Source: 0.2891, Validation Loss Target: 0.6797\n",
      "Epoch 7, Batch 10/34, Total Loss: 0.5899, Segmentation Loss: 0.1550, Domain Loss Source: 0.3937, Domain Loss Target: 0.0481, Adversarial Loss Target: 0.0030\n",
      "Epoch 7, Batch 20/34, Total Loss: 0.5841, Segmentation Loss: 0.1495, Domain Loss Source: 0.1619, Domain Loss Target: 0.3052, Adversarial Loss Target: 0.0009\n",
      "Epoch 7, Batch 30/34, Total Loss: 0.5380, Segmentation Loss: 0.1232, Domain Loss Source: 0.2105, Domain Loss Target: 0.1323, Adversarial Loss Target: 0.0015\n",
      "Epoch 7, Train Loss: 2.9213\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.8992, Recall: 0.5114, F1 Score: 0.6480, Dice Score: 0.6480, Accuracy: 0.9040\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.5263, Recall: 0.7074, F1 Score: 0.5926, Dice Score: 0.5926, Accuracy: 0.8112\n",
      "Epoch 7, Validation Loss Source: 0.2919, Validation Loss Target: 0.6996\n",
      "Epoch 8, Batch 10/34, Total Loss: 0.5777, Segmentation Loss: 0.1456, Domain Loss Source: 0.0848, Domain Loss Target: 0.3307, Adversarial Loss Target: 0.0009\n",
      "Epoch 8, Batch 20/34, Total Loss: 0.5789, Segmentation Loss: 0.1421, Domain Loss Source: 0.1292, Domain Loss Target: 0.3300, Adversarial Loss Target: 0.0008\n",
      "Epoch 8, Batch 30/34, Total Loss: 0.5645, Segmentation Loss: 0.1154, Domain Loss Source: 0.1321, Domain Loss Target: 0.3084, Adversarial Loss Target: 0.0007\n",
      "Epoch 8, Train Loss: 2.9250\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.8936, Recall: 0.5267, F1 Score: 0.6590, Dice Score: 0.6590, Accuracy: 0.9058\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.5186, Recall: 0.7212, F1 Score: 0.5923, Dice Score: 0.5923, Accuracy: 0.8069\n",
      "Epoch 8, Validation Loss Source: 0.2874, Validation Loss Target: 0.7534\n",
      "Epoch 9, Batch 10/34, Total Loss: 0.5261, Segmentation Loss: 0.1383, Domain Loss Source: 0.2960, Domain Loss Target: 0.1081, Adversarial Loss Target: 0.0019\n",
      "Epoch 9, Batch 20/34, Total Loss: 0.5470, Segmentation Loss: 0.1352, Domain Loss Source: 0.3232, Domain Loss Target: 0.1489, Adversarial Loss Target: 0.0014\n",
      "Epoch 9, Batch 30/34, Total Loss: 0.5350, Segmentation Loss: 0.1087, Domain Loss Source: 0.2148, Domain Loss Target: 0.1058, Adversarial Loss Target: 0.0020\n",
      "Epoch 9, Train Loss: 2.7853\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.8990, Recall: 0.5147, F1 Score: 0.6508, Dice Score: 0.6508, Accuracy: 0.9046\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.5213, Recall: 0.7221, F1 Score: 0.5944, Dice Score: 0.5944, Accuracy: 0.8086\n",
      "Epoch 9, Validation Loss Source: 0.3082, Validation Loss Target: 0.7848\n",
      "Epoch 10, Batch 10/34, Total Loss: 0.5035, Segmentation Loss: 0.1316, Domain Loss Source: 0.1043, Domain Loss Target: 0.3395, Adversarial Loss Target: 0.0008\n",
      "Epoch 10, Batch 20/34, Total Loss: 0.5019, Segmentation Loss: 0.1286, Domain Loss Source: 0.1589, Domain Loss Target: 0.1747, Adversarial Loss Target: 0.0017\n",
      "Epoch 10, Batch 30/34, Total Loss: 0.4754, Segmentation Loss: 0.1025, Domain Loss Source: 0.1172, Domain Loss Target: 0.1213, Adversarial Loss Target: 0.0017\n",
      "Epoch 10, Train Loss: 2.5654\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.9045, Recall: 0.4944, F1 Score: 0.6354, Dice Score: 0.6354, Accuracy: 0.9020\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.5325, Recall: 0.7076, F1 Score: 0.6006, Dice Score: 0.6006, Accuracy: 0.8177\n",
      "Epoch 10, Validation Loss Source: 0.3358, Validation Loss Target: 0.7824\n",
      "Precision: 0.5325, Recall: 0.7076, F1 Score: 0.6006, Dice Score: 0.6006, Accuracy: 0.8177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61410b8ffce45de8c1d2df2a4a1376f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3140.881 MB of 3140.881 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dice_score/source</td><td></td></tr><tr><td>dice_score/target</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>precision/source</td><td></td></tr><tr><td>precision/target</td><td> </td></tr><tr><td>test/accuracy</td><td></td></tr><tr><td>test/dice_score</td><td></td></tr><tr><td>test/f1_score</td><td></td></tr><tr><td>test/precision</td><td></td></tr><tr><td>test/recall</td><td></td></tr><tr><td>train/domain_loss</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>val/loss_source</td><td></td></tr><tr><td>val/loss_target</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dice_score/source</td><td>0.63538</td></tr><tr><td>dice_score/target</td><td>0.60058</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>precision/source</td><td>0.90452</td></tr><tr><td>precision/target</td><td>0.53252</td></tr><tr><td>test/accuracy</td><td>0.81768</td></tr><tr><td>test/dice_score</td><td>0.60058</td></tr><tr><td>test/f1_score</td><td>0.60058</td></tr><tr><td>test/precision</td><td>0.53252</td></tr><tr><td>test/recall</td><td>0.7076</td></tr><tr><td>train/domain_loss</td><td>0.36723</td></tr><tr><td>train/loss</td><td>2.56542</td></tr><tr><td>val/loss_source</td><td>0.33583</td></tr><tr><td>val/loss_target</td><td>0.78236</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">FADA-Linknet-timm-regnetx_320-window_500-600_pretrained-augmented_target-random_crops_bloodvessel_ratio01</strong> at: <a href='https://wandb.ai/idp2024/supervised-domain-adaptation/runs/qd45bcaj' target=\"_blank\">https://wandb.ai/idp2024/supervised-domain-adaptation/runs/qd45bcaj</a><br/> View project at: <a href='https://wandb.ai/idp2024/supervised-domain-adaptation' target=\"_blank\">https://wandb.ai/idp2024/supervised-domain-adaptation</a><br/>Synced 5 W&B file(s), 150 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241113_215941-qd45bcaj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from FADA.train_FADA_supervised import model_pipeline\n",
    "\n",
    "train_indices = [0]\n",
    "trainloader_target_labeled = DataLoader(\n",
    "    Subset(testset, train_indices),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "testloader_target = DataLoader(\n",
    "    Subset(testset, list({0, 1, 2, 3, 4} - set(train_indices))),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "encoder = \"timm-regnetx_320\"\n",
    "architecture = \"Linknet\"\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "loss = \"BCE\"\n",
    "in_channels = 1\n",
    "ndf = 512\n",
    "learning_rate_fea = 0.001\n",
    "learning_rate_cls = 0.001\n",
    "learning_rate_dis = 0.0001\n",
    "\n",
    "config = {\n",
    "    \"model\": \"FADA-{architecture}-{encoder}-window_{window[0]}-{window[1]}_pretrained-augmented_target-random_crops_bloodvessel_ratio01\".format(\n",
    "        architecture=architecture, encoder=encoder, window=window\n",
    "    ),\n",
    "    \"encoder\": encoder,\n",
    "    \"architecture\": architecture,\n",
    "    \"in_channels\": in_channels,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"batch_size_source\": trainloader_source.batch_size,\n",
    "    \"batch_size_target\": trainloader_target.batch_size,\n",
    "    \"learning_rate_fea\": learning_rate_fea,\n",
    "    \"learning_rate_cls\": learning_rate_cls,\n",
    "    \"learning_rate_dis\": learning_rate_dis,\n",
    "    \"ndf\": ndf,\n",
    "    \"epochs\": epochs,\n",
    "    \"seg_loss\": loss,\n",
    "    \"pretrained\": \"./models/Linknet-timm-regnetx_320-512x512-augmented-with-random-crops-single-channel-focal.pth\",\n",
    "    \"target_augmented\": target_augmented,\n",
    "    \"train_indices\": train_indices,\n",
    "}\n",
    "\n",
    "\n",
    "model, train_losses, domain_losses, val_losses_source, val_losses_target = (\n",
    "    model_pipeline(\n",
    "        trainloader_source,\n",
    "        validationloader_source,\n",
    "        testloader_source,\n",
    "        trainloader_target_labeled,\n",
    "        trainloader_target,\n",
    "        testloader_target,\n",
    "        config,\n",
    "        project=\"supervised-domain-adaptation\",\n",
    "        device=device,\n",
    "        batch_print=10,\n",
    "        evaluate=True,\n",
    "        with_overlays=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label=\"Combined Training Loss\")\n",
    "plt.plot(domain_losses, label=\"Domain Loss\")\n",
    "plt.plot(val_losses_source, label=\"Validation Loss Source\")\n",
    "plt.plot(val_losses_target, label=\"Validation Loss Target\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Curves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtim-mach\u001b[0m (\u001b[33midp2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/home/tim_ivan/idp/wandb/run-20250115_122822-yet20tct</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idp2024/hsi-autoencoder/runs/yet20tct' target=\"_blank\">gcr-comic-sweep-trained-longer</a></strong> to <a href='https://wandb.ai/idp2024/hsi-autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idp2024/hsi-autoencoder' target=\"_blank\">https://wandb.ai/idp2024/hsi-autoencoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idp2024/hsi-autoencoder/runs/yet20tct' target=\"_blank\">https://wandb.ai/idp2024/hsi-autoencoder/runs/yet20tct</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 5, Loss: 0.2909\n",
      "Epoch 1, Batch 10, Loss: 0.2733\n",
      "Epoch 1, Batch 15, Loss: 0.2472\n",
      "Epoch 1, Train Loss: 0.2650\n",
      "Precision: 0.4655, Recall: 0.4525, F1 Score: 0.4482, Dice Score: 0.4482, Accuracy: 0.7844\n",
      "Epoch 1, Validation Loss: 0.5848\n",
      "Epoch 2, Batch 5, Loss: 0.2467\n",
      "Epoch 2, Batch 10, Loss: 0.2359\n",
      "Epoch 2, Batch 15, Loss: 0.2991\n",
      "Epoch 2, Train Loss: 0.2607\n",
      "Precision: 0.4654, Recall: 0.4529, F1 Score: 0.4484, Dice Score: 0.4484, Accuracy: 0.7843\n",
      "Epoch 2, Validation Loss: 0.5796\n",
      "Epoch 3, Batch 5, Loss: 0.2650\n",
      "Epoch 3, Batch 10, Loss: 0.2774\n",
      "Epoch 3, Batch 15, Loss: 0.2412\n",
      "Epoch 3, Train Loss: 0.2622\n",
      "Precision: 0.4653, Recall: 0.4533, F1 Score: 0.4486, Dice Score: 0.4486, Accuracy: 0.7843\n",
      "Epoch 3, Validation Loss: 0.5740\n",
      "Epoch 4, Batch 5, Loss: 0.2247\n",
      "Epoch 4, Batch 10, Loss: 0.2669\n",
      "Epoch 4, Batch 15, Loss: 0.2823\n",
      "Epoch 4, Train Loss: 0.2642\n",
      "Precision: 0.4651, Recall: 0.4537, F1 Score: 0.4487, Dice Score: 0.4487, Accuracy: 0.7842\n",
      "Epoch 4, Validation Loss: 0.5687\n",
      "Epoch 5, Batch 5, Loss: 0.2611\n",
      "Epoch 5, Batch 10, Loss: 0.2618\n",
      "Epoch 5, Batch 15, Loss: 0.2594\n",
      "Epoch 5, Train Loss: 0.2532\n",
      "Precision: 0.4647, Recall: 0.4537, F1 Score: 0.4486, Dice Score: 0.4486, Accuracy: 0.7841\n",
      "Epoch 5, Validation Loss: 0.5631\n",
      "Epoch 6, Batch 5, Loss: 0.2551\n",
      "Epoch 6, Batch 10, Loss: 0.2460\n",
      "Epoch 6, Batch 15, Loss: 0.2792\n",
      "Epoch 6, Train Loss: 0.2542\n",
      "Precision: 0.4644, Recall: 0.4538, F1 Score: 0.4485, Dice Score: 0.4485, Accuracy: 0.7840\n",
      "Epoch 6, Validation Loss: 0.5579\n",
      "Epoch 7, Batch 5, Loss: 0.2596\n",
      "Epoch 7, Batch 10, Loss: 0.2508\n",
      "Epoch 7, Batch 15, Loss: 0.2467\n",
      "Epoch 7, Train Loss: 0.2550\n",
      "Precision: 0.4643, Recall: 0.4539, F1 Score: 0.4485, Dice Score: 0.4485, Accuracy: 0.7840\n",
      "Epoch 7, Validation Loss: 0.5527\n",
      "Epoch 8, Batch 5, Loss: 0.2466\n",
      "Epoch 8, Batch 10, Loss: 0.2848\n",
      "Epoch 8, Batch 15, Loss: 0.2230\n",
      "Epoch 8, Train Loss: 0.2508\n",
      "Precision: 0.4641, Recall: 0.4541, F1 Score: 0.4485, Dice Score: 0.4485, Accuracy: 0.7839\n",
      "Epoch 8, Validation Loss: 0.5475\n",
      "Epoch 9, Batch 5, Loss: 0.2385\n",
      "Epoch 9, Batch 10, Loss: 0.2187\n",
      "Epoch 9, Batch 15, Loss: 0.2962\n",
      "Epoch 9, Train Loss: 0.2464\n",
      "Precision: 0.4640, Recall: 0.4544, F1 Score: 0.4486, Dice Score: 0.4486, Accuracy: 0.7838\n",
      "Epoch 9, Validation Loss: 0.5426\n",
      "Epoch 10, Batch 5, Loss: 0.2100\n",
      "Epoch 10, Batch 10, Loss: 0.2520\n",
      "Epoch 10, Batch 15, Loss: 0.2724\n",
      "Epoch 10, Train Loss: 0.2436\n",
      "Precision: 0.4638, Recall: 0.4545, F1 Score: 0.4486, Dice Score: 0.4486, Accuracy: 0.7838\n",
      "Epoch 10, Validation Loss: 0.5376\n",
      "Epoch 11, Batch 5, Loss: 0.2494\n",
      "Epoch 11, Batch 10, Loss: 0.2227\n",
      "Epoch 11, Batch 15, Loss: 0.2504\n",
      "Epoch 11, Train Loss: 0.2461\n",
      "Precision: 0.4636, Recall: 0.4546, F1 Score: 0.4486, Dice Score: 0.4486, Accuracy: 0.7837\n",
      "Epoch 11, Validation Loss: 0.5325\n",
      "Epoch 12, Batch 5, Loss: 0.2328\n",
      "Epoch 12, Batch 10, Loss: 0.2703\n",
      "Epoch 12, Batch 15, Loss: 0.2372\n",
      "Epoch 12, Train Loss: 0.2396\n",
      "Precision: 0.4635, Recall: 0.4546, F1 Score: 0.4485, Dice Score: 0.4485, Accuracy: 0.7836\n",
      "Epoch 12, Validation Loss: 0.5275\n",
      "Epoch 13, Batch 5, Loss: 0.2421\n",
      "Epoch 13, Batch 10, Loss: 0.2131\n",
      "Epoch 13, Batch 15, Loss: 0.2553\n",
      "Epoch 13, Train Loss: 0.2383\n",
      "Precision: 0.4633, Recall: 0.4548, F1 Score: 0.4485, Dice Score: 0.4485, Accuracy: 0.7835\n",
      "Epoch 13, Validation Loss: 0.5227\n",
      "Epoch 14, Batch 5, Loss: 0.2226\n",
      "Epoch 14, Batch 10, Loss: 0.2623\n",
      "Epoch 14, Batch 15, Loss: 0.2304\n",
      "Epoch 14, Train Loss: 0.2350\n",
      "Precision: 0.4633, Recall: 0.4550, F1 Score: 0.4486, Dice Score: 0.4486, Accuracy: 0.7836\n",
      "Epoch 14, Validation Loss: 0.5179\n",
      "Epoch 15, Batch 5, Loss: 0.2548\n",
      "Epoch 15, Batch 10, Loss: 0.2548\n",
      "Epoch 15, Batch 15, Loss: 0.2125\n",
      "Epoch 15, Train Loss: 0.2371\n",
      "Precision: 0.4633, Recall: 0.4551, F1 Score: 0.4487, Dice Score: 0.4487, Accuracy: 0.7836\n",
      "Epoch 15, Validation Loss: 0.5130\n",
      "Epoch 16, Batch 5, Loss: 0.2231\n",
      "Epoch 16, Batch 10, Loss: 0.2863\n",
      "Epoch 16, Batch 15, Loss: 0.1922\n",
      "Epoch 16, Train Loss: 0.2286\n",
      "Precision: 0.4634, Recall: 0.4553, F1 Score: 0.4488, Dice Score: 0.4488, Accuracy: 0.7836\n",
      "Epoch 16, Validation Loss: 0.5082\n",
      "Epoch 17, Batch 5, Loss: 0.2471\n",
      "Epoch 17, Batch 10, Loss: 0.2156\n",
      "Epoch 17, Batch 15, Loss: 0.2230\n",
      "Epoch 17, Train Loss: 0.2339\n",
      "Precision: 0.4633, Recall: 0.4553, F1 Score: 0.4488, Dice Score: 0.4488, Accuracy: 0.7836\n",
      "Epoch 17, Validation Loss: 0.5037\n",
      "Epoch 18, Batch 5, Loss: 0.1872\n",
      "Epoch 18, Batch 10, Loss: 0.2095\n",
      "Epoch 18, Batch 15, Loss: 0.2693\n",
      "Epoch 18, Train Loss: 0.2261\n",
      "Precision: 0.4633, Recall: 0.4551, F1 Score: 0.4487, Dice Score: 0.4487, Accuracy: 0.7836\n",
      "Epoch 18, Validation Loss: 0.4992\n",
      "Epoch 19, Batch 5, Loss: 0.2473\n",
      "Epoch 19, Batch 10, Loss: 0.2200\n",
      "Epoch 19, Batch 15, Loss: 0.2048\n",
      "Epoch 19, Train Loss: 0.2294\n",
      "Precision: 0.4632, Recall: 0.4551, F1 Score: 0.4487, Dice Score: 0.4487, Accuracy: 0.7835\n",
      "Epoch 19, Validation Loss: 0.4945\n",
      "Epoch 20, Batch 5, Loss: 0.2094\n",
      "Epoch 20, Batch 10, Loss: 0.2083\n",
      "Epoch 20, Batch 15, Loss: 0.2405\n",
      "Epoch 20, Train Loss: 0.2180\n",
      "Precision: 0.4629, Recall: 0.4548, F1 Score: 0.4484, Dice Score: 0.4484, Accuracy: 0.7834\n",
      "Epoch 20, Validation Loss: 0.4900\n",
      "Epoch 21, Batch 5, Loss: 0.2271\n",
      "Epoch 21, Batch 10, Loss: 0.2160\n",
      "Epoch 21, Batch 15, Loss: 0.2136\n",
      "Epoch 21, Train Loss: 0.2206\n",
      "Precision: 0.4629, Recall: 0.4545, F1 Score: 0.4482, Dice Score: 0.4482, Accuracy: 0.7834\n",
      "Epoch 21, Validation Loss: 0.4855\n",
      "Epoch 22, Batch 5, Loss: 0.2575\n",
      "Epoch 22, Batch 10, Loss: 0.2072\n",
      "Epoch 22, Batch 15, Loss: 0.1910\n",
      "Epoch 22, Train Loss: 0.2216\n",
      "Precision: 0.4628, Recall: 0.4539, F1 Score: 0.4479, Dice Score: 0.4479, Accuracy: 0.7834\n",
      "Epoch 22, Validation Loss: 0.4810\n",
      "Epoch 23, Batch 5, Loss: 0.1905\n",
      "Epoch 23, Batch 10, Loss: 0.2378\n",
      "Epoch 23, Batch 15, Loss: 0.2174\n",
      "Epoch 23, Train Loss: 0.2168\n",
      "Precision: 0.4625, Recall: 0.4533, F1 Score: 0.4475, Dice Score: 0.4475, Accuracy: 0.7833\n",
      "Epoch 23, Validation Loss: 0.4767\n",
      "Epoch 24, Batch 5, Loss: 0.2465\n",
      "Epoch 24, Batch 10, Loss: 0.2047\n",
      "Epoch 24, Batch 15, Loss: 0.1919\n",
      "Epoch 24, Train Loss: 0.2075\n",
      "Precision: 0.4625, Recall: 0.4525, F1 Score: 0.4471, Dice Score: 0.4471, Accuracy: 0.7833\n",
      "Epoch 24, Validation Loss: 0.4722\n",
      "Epoch 25, Batch 5, Loss: 0.2189\n",
      "Epoch 25, Batch 10, Loss: 0.2125\n",
      "Epoch 25, Batch 15, Loss: 0.2054\n",
      "Epoch 25, Train Loss: 0.2100\n",
      "Precision: 0.4625, Recall: 0.4517, F1 Score: 0.4467, Dice Score: 0.4467, Accuracy: 0.7833\n",
      "Epoch 25, Validation Loss: 0.4681\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca89fd04b61b44729c17a1952b67ab66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.146 MB of 2.146 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dice_score</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>precision</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>validation/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dice_score</td><td>0.44666</td></tr><tr><td>epoch</td><td>25</td></tr><tr><td>precision</td><td>0.46247</td></tr><tr><td>train/loss</td><td>0.20998</td></tr><tr><td>validation/loss</td><td>0.46807</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gcr-comic-sweep-trained-longer</strong> at: <a href='https://wandb.ai/idp2024/hsi-autoencoder/runs/yet20tct' target=\"_blank\">https://wandb.ai/idp2024/hsi-autoencoder/runs/yet20tct</a><br/> View project at: <a href='https://wandb.ai/idp2024/hsi-autoencoder' target=\"_blank\">https://wandb.ai/idp2024/hsi-autoencoder</a><br/>Synced 5 W&B file(s), 50 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250115_122822-yet20tct/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(GaussianAutoEncoder(\n",
       "   (encoder): GaussianChannelReduction()\n",
       "   (decoder): Sequential(\n",
       "     (0): Conv2d(3, 826, kernel_size=(1, 1), stride=(1, 1))\n",
       "   )\n",
       " ),\n",
       " [0.26498704589903355,\n",
       "  0.26065779477357864,\n",
       "  0.26216429099440575,\n",
       "  0.2642474053427577,\n",
       "  0.25316854286938906,\n",
       "  0.2541518956422806,\n",
       "  0.25495866034179926,\n",
       "  0.25081960670650005,\n",
       "  0.24636503402143717,\n",
       "  0.24360113125294447,\n",
       "  0.24611327424645424,\n",
       "  0.23962208162993193,\n",
       "  0.23826881125569344,\n",
       "  0.2349787252023816,\n",
       "  0.2370747309178114,\n",
       "  0.22864695638418198,\n",
       "  0.23393349163234234,\n",
       "  0.22605776879936457,\n",
       "  0.22936534835025668,\n",
       "  0.2180381240323186,\n",
       "  0.22055898141115904,\n",
       "  0.2216031150892377,\n",
       "  0.21681103017181158,\n",
       "  0.20754558499902487,\n",
       "  0.2099823895841837],\n",
       " [0.584813916683197,\n",
       "  0.5795517534017562,\n",
       "  0.5740000367164612,\n",
       "  0.5687262386083602,\n",
       "  0.56311194896698,\n",
       "  0.5579179108142853,\n",
       "  0.5527239143848419,\n",
       "  0.5474654883146286,\n",
       "  0.5425585150718689,\n",
       "  0.5375813484191895,\n",
       "  0.5325294882059097,\n",
       "  0.5274864673614502,\n",
       "  0.5226892530918121,\n",
       "  0.5178719848394394,\n",
       "  0.5129738032817841,\n",
       "  0.5081985890865326,\n",
       "  0.5036927103996277,\n",
       "  0.4992492079734802,\n",
       "  0.49451372027397156,\n",
       "  0.4899649441242218,\n",
       "  0.4855357617139816,\n",
       "  0.48095378577709197,\n",
       "  0.4766536295413971,\n",
       "  0.4721909373998642,\n",
       "  0.4680668652057648])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import build_hsi_dataloader, HSIDataset, build_hsi_testloader\n",
    "from dimensionality_reduction.autoencoder import (\n",
    "    GaussianAutoEncoder,\n",
    "    model_pipeline_autoencoder,\n",
    "    build_and_store_gcr,\n",
    ")\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = {\n",
    "    \"model\": \"gcr-comic-sweep-trained-longer\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"lr_encoder\": 0.003991856255637263,\n",
    "    \"lr_decoder\": 0.0001405199848490131,\n",
    "    \"batch_size\": 4,\n",
    "    \"epochs\": 25,\n",
    "    \"mu\": [335, 267, 131],\n",
    "    \"sigma\": [1, 1, 1],\n",
    "}\n",
    "\n",
    "model_pipeline_autoencoder(\n",
    "    config,\n",
    "    project=\"hsi-autoencoder\",\n",
    "    epochs=25,\n",
    "    device=device,\n",
    "    batch_print=5,\n",
    "    save_wandb=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian reduction + DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 534, validation set: 60\n",
      "Number of samples in the test set: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtim-mach\u001b[0m (\u001b[33midp2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/home/tim_ivan/idp/wandb/run-20250115_115413-9ebzcxi7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idp2024/domain-adaptation/runs/9ebzcxi7' target=\"_blank\">FADA-Linknet-timm-regnetx_320-gcr_comic-sweep_pretrained-augmented_target-random_crops_bloodvessel_ratio01-unsupervised</a></strong> to <a href='https://wandb.ai/idp2024/domain-adaptation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idp2024/domain-adaptation' target=\"_blank\">https://wandb.ai/idp2024/domain-adaptation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idp2024/domain-adaptation/runs/9ebzcxi7' target=\"_blank\">https://wandb.ai/idp2024/domain-adaptation/runs/9ebzcxi7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from ./models/serene-sweep-9.pth\n",
      "Using Gaussian Channel Reduction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 5/34, Total Loss: 4.9166, Segmentation Loss: 0.2590, Domain Loss Source: 0.0000, Domain Loss Target: 9.0312, Adversarial Loss Target: 0.0000\n",
      "Epoch 1, Batch 10/34, Total Loss: 1.7854, Segmentation Loss: 0.2620, Domain Loss Source: 0.2797, Domain Loss Target: 0.3624, Adversarial Loss Target: 0.0006\n",
      "Epoch 1, Batch 15/34, Total Loss: 1.1583, Segmentation Loss: 0.2092, Domain Loss Source: 0.7618, Domain Loss Target: 0.1001, Adversarial Loss Target: 0.0016\n",
      "Epoch 1, Batch 20/34, Total Loss: 0.9656, Segmentation Loss: 0.2295, Domain Loss Source: 0.1748, Domain Loss Target: 0.5135, Adversarial Loss Target: 0.0004\n",
      "Epoch 1, Batch 25/34, Total Loss: 0.8674, Segmentation Loss: 0.1388, Domain Loss Source: 0.1911, Domain Loss Target: 0.4740, Adversarial Loss Target: 0.0004\n",
      "Epoch 1, Batch 30/34, Total Loss: 0.8252, Segmentation Loss: 0.1460, Domain Loss Source: 0.4454, Domain Loss Target: 0.2020, Adversarial Loss Target: 0.0009\n",
      "Epoch 1, Train Loss: 4.7005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home/tim_ivan/idp/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model performance on source data\n",
      "Precision: 0.9181, Recall: 0.5615, F1 Score: 0.6948, Dice Score: 0.6948, Accuracy: 0.9147\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.5151, Recall: 0.5436, F1 Score: 0.5246, Dice Score: 0.5246, Accuracy: 0.8072\n",
      "Epoch 1, Validation Loss Source: 0.2797, Validation Loss Target: 0.8326\n",
      "Epoch 2, Batch 5/34, Total Loss: 0.7925, Segmentation Loss: 0.2047, Domain Loss Source: 0.2247, Domain Loss Target: 0.3877, Adversarial Loss Target: 0.0005\n",
      "Epoch 2, Batch 10/34, Total Loss: 0.7661, Segmentation Loss: 0.1439, Domain Loss Source: 0.3419, Domain Loss Target: 0.2884, Adversarial Loss Target: 0.0007\n",
      "Epoch 2, Batch 15/34, Total Loss: 0.7512, Segmentation Loss: 0.1254, Domain Loss Source: 0.3471, Domain Loss Target: 0.2665, Adversarial Loss Target: 0.0007\n",
      "Epoch 2, Batch 20/34, Total Loss: 0.7387, Segmentation Loss: 0.1365, Domain Loss Source: 0.3221, Domain Loss Target: 0.2717, Adversarial Loss Target: 0.0007\n",
      "Epoch 2, Batch 25/34, Total Loss: 0.7085, Segmentation Loss: 0.0939, Domain Loss Source: 0.3186, Domain Loss Target: 0.2585, Adversarial Loss Target: 0.0008\n",
      "Epoch 2, Batch 30/34, Total Loss: 0.7002, Segmentation Loss: 0.1168, Domain Loss Source: 0.2381, Domain Loss Target: 0.3108, Adversarial Loss Target: 0.0007\n",
      "Epoch 2, Train Loss: 2.1763\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.8811, Recall: 0.6730, F1 Score: 0.7617, Dice Score: 0.7617, Accuracy: 0.9271\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.4871, Recall: 0.6093, F1 Score: 0.5336, Dice Score: 0.5336, Accuracy: 0.7912\n",
      "Epoch 2, Validation Loss Source: 0.2478, Validation Loss Target: 1.0133\n",
      "Epoch 3, Batch 5/34, Total Loss: 0.7161, Segmentation Loss: 0.1902, Domain Loss Source: 0.2002, Domain Loss Target: 0.4075, Adversarial Loss Target: 0.0005\n",
      "Epoch 3, Batch 10/34, Total Loss: 0.7257, Segmentation Loss: 0.1328, Domain Loss Source: 0.2546, Domain Loss Target: 0.3355, Adversarial Loss Target: 0.0006\n",
      "Epoch 3, Batch 15/34, Total Loss: 0.6963, Segmentation Loss: 0.1133, Domain Loss Source: 0.2591, Domain Loss Target: 0.3079, Adversarial Loss Target: 0.0007\n",
      "Epoch 3, Batch 20/34, Total Loss: 0.6831, Segmentation Loss: 0.1181, Domain Loss Source: 0.1850, Domain Loss Target: 0.3804, Adversarial Loss Target: 0.0006\n",
      "Epoch 3, Batch 25/34, Total Loss: 0.6801, Segmentation Loss: 0.0837, Domain Loss Source: 0.2349, Domain Loss Target: 0.2802, Adversarial Loss Target: 0.0007\n",
      "Epoch 3, Batch 30/34, Total Loss: 0.6708, Segmentation Loss: 0.1048, Domain Loss Source: 0.2718, Domain Loss Target: 0.2372, Adversarial Loss Target: 0.0009\n",
      "Epoch 3, Train Loss: 2.0331\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.8845, Recall: 0.6778, F1 Score: 0.7660, Dice Score: 0.7660, Accuracy: 0.9283\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.4830, Recall: 0.6323, F1 Score: 0.5425, Dice Score: 0.5425, Accuracy: 0.7911\n",
      "Epoch 3, Validation Loss Source: 0.2627, Validation Loss Target: 0.9941\n",
      "Epoch 4, Batch 5/34, Total Loss: 0.6564, Segmentation Loss: 0.1811, Domain Loss Source: 0.2166, Domain Loss Target: 0.3094, Adversarial Loss Target: 0.0008\n",
      "Epoch 4, Batch 10/34, Total Loss: 0.6701, Segmentation Loss: 0.1168, Domain Loss Source: 0.2680, Domain Loss Target: 0.2639, Adversarial Loss Target: 0.0008\n",
      "Epoch 4, Batch 15/34, Total Loss: 0.6695, Segmentation Loss: 0.1051, Domain Loss Source: 0.3614, Domain Loss Target: 0.1729, Adversarial Loss Target: 0.0011\n",
      "Epoch 4, Batch 20/34, Total Loss: 0.6389, Segmentation Loss: 0.0988, Domain Loss Source: 0.2988, Domain Loss Target: 0.2088, Adversarial Loss Target: 0.0011\n",
      "Epoch 4, Batch 25/34, Total Loss: 0.6265, Segmentation Loss: 0.0745, Domain Loss Source: 0.1813, Domain Loss Target: 0.3039, Adversarial Loss Target: 0.0007\n",
      "Epoch 4, Batch 30/34, Total Loss: 0.6656, Segmentation Loss: 0.0976, Domain Loss Source: 0.1454, Domain Loss Target: 0.5026, Adversarial Loss Target: 0.0004\n",
      "Epoch 4, Train Loss: 1.9180\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.8861, Recall: 0.6968, F1 Score: 0.7787, Dice Score: 0.7787, Accuracy: 0.9315\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.4747, Recall: 0.6694, F1 Score: 0.5479, Dice Score: 0.5479, Accuracy: 0.7825\n",
      "Epoch 4, Validation Loss Source: 0.2506, Validation Loss Target: 1.0308\n",
      "Epoch 5, Batch 5/34, Total Loss: 0.6880, Segmentation Loss: 0.1709, Domain Loss Source: 0.1718, Domain Loss Target: 0.3618, Adversarial Loss Target: 0.0006\n",
      "Epoch 5, Batch 10/34, Total Loss: 0.6626, Segmentation Loss: 0.1075, Domain Loss Source: 0.2853, Domain Loss Target: 0.2304, Adversarial Loss Target: 0.0009\n",
      "Epoch 5, Batch 15/34, Total Loss: 0.6417, Segmentation Loss: 0.0980, Domain Loss Source: 0.2724, Domain Loss Target: 0.2464, Adversarial Loss Target: 0.0009\n",
      "Epoch 5, Batch 20/34, Total Loss: 0.6587, Segmentation Loss: 0.0908, Domain Loss Source: 0.1659, Domain Loss Target: 0.4953, Adversarial Loss Target: 0.0004\n",
      "Epoch 5, Batch 25/34, Total Loss: 0.6304, Segmentation Loss: 0.0683, Domain Loss Source: 0.2530, Domain Loss Target: 0.3145, Adversarial Loss Target: 0.0007\n",
      "Epoch 5, Batch 30/34, Total Loss: 0.6607, Segmentation Loss: 0.0889, Domain Loss Source: 0.3747, Domain Loss Target: 0.1586, Adversarial Loss Target: 0.0012\n",
      "Epoch 5, Train Loss: 1.9191\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.8880, Recall: 0.6918, F1 Score: 0.7763, Dice Score: 0.7763, Accuracy: 0.9311\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.4831, Recall: 0.6623, F1 Score: 0.5519, Dice Score: 0.5519, Accuracy: 0.7885\n",
      "Epoch 5, Validation Loss Source: 0.2695, Validation Loss Target: 1.0361\n",
      "Epoch 6, Batch 5/34, Total Loss: 0.6295, Segmentation Loss: 0.1648, Domain Loss Source: 0.2762, Domain Loss Target: 0.2107, Adversarial Loss Target: 0.0011\n",
      "Epoch 6, Batch 10/34, Total Loss: 0.6384, Segmentation Loss: 0.0996, Domain Loss Source: 0.2193, Domain Loss Target: 0.3786, Adversarial Loss Target: 0.0006\n",
      "Epoch 6, Batch 15/34, Total Loss: 0.6441, Segmentation Loss: 0.0903, Domain Loss Source: 0.2671, Domain Loss Target: 0.3363, Adversarial Loss Target: 0.0007\n",
      "Epoch 6, Batch 20/34, Total Loss: 0.6363, Segmentation Loss: 0.0837, Domain Loss Source: 0.1336, Domain Loss Target: 0.4264, Adversarial Loss Target: 0.0005\n",
      "Epoch 6, Batch 25/34, Total Loss: 0.5937, Segmentation Loss: 0.0627, Domain Loss Source: 0.3027, Domain Loss Target: 0.1843, Adversarial Loss Target: 0.0011\n",
      "Epoch 6, Batch 30/34, Total Loss: 0.5810, Segmentation Loss: 0.0835, Domain Loss Source: 0.2773, Domain Loss Target: 0.2028, Adversarial Loss Target: 0.0011\n",
      "Epoch 6, Train Loss: 1.8111\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.8885, Recall: 0.7067, F1 Score: 0.7858, Dice Score: 0.7858, Accuracy: 0.9335\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.4742, Recall: 0.6804, F1 Score: 0.5518, Dice Score: 0.5518, Accuracy: 0.7820\n",
      "Epoch 6, Validation Loss Source: 0.2695, Validation Loss Target: 1.1120\n",
      "Epoch 7, Batch 5/34, Total Loss: 0.6945, Segmentation Loss: 0.1600, Domain Loss Source: 0.4663, Domain Loss Target: 0.1347, Adversarial Loss Target: 0.0014\n",
      "Epoch 7, Batch 10/34, Total Loss: 0.6278, Segmentation Loss: 0.0893, Domain Loss Source: 0.3857, Domain Loss Target: 0.1469, Adversarial Loss Target: 0.0013\n",
      "Epoch 7, Batch 15/34, Total Loss: 0.6415, Segmentation Loss: 0.0836, Domain Loss Source: 0.3329, Domain Loss Target: 0.1691, Adversarial Loss Target: 0.0012\n",
      "Epoch 7, Batch 20/34, Total Loss: 0.6178, Segmentation Loss: 0.0768, Domain Loss Source: 0.2314, Domain Loss Target: 0.2417, Adversarial Loss Target: 0.0009\n",
      "Epoch 7, Batch 25/34, Total Loss: 0.5680, Segmentation Loss: 0.0578, Domain Loss Source: 0.2548, Domain Loss Target: 0.1918, Adversarial Loss Target: 0.0011\n",
      "Epoch 7, Batch 30/34, Total Loss: 0.5553, Segmentation Loss: 0.0779, Domain Loss Source: 0.2827, Domain Loss Target: 0.1884, Adversarial Loss Target: 0.0012\n",
      "Epoch 7, Train Loss: 1.8124\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.8858, Recall: 0.7139, F1 Score: 0.7892, Dice Score: 0.7892, Accuracy: 0.9341\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.4705, Recall: 0.6863, F1 Score: 0.5511, Dice Score: 0.5511, Accuracy: 0.7794\n",
      "Epoch 7, Validation Loss Source: 0.2773, Validation Loss Target: 1.1727\n",
      "Epoch 8, Batch 5/34, Total Loss: 0.6144, Segmentation Loss: 0.1558, Domain Loss Source: 0.4087, Domain Loss Target: 0.1096, Adversarial Loss Target: 0.0015\n",
      "Epoch 8, Batch 10/34, Total Loss: 0.5753, Segmentation Loss: 0.0828, Domain Loss Source: 0.3803, Domain Loss Target: 0.1383, Adversarial Loss Target: 0.0014\n",
      "Epoch 8, Batch 15/34, Total Loss: 0.5930, Segmentation Loss: 0.0777, Domain Loss Source: 0.1945, Domain Loss Target: 0.2881, Adversarial Loss Target: 0.0009\n",
      "Epoch 8, Batch 20/34, Total Loss: 0.6225, Segmentation Loss: 0.0723, Domain Loss Source: 0.1336, Domain Loss Target: 0.3538, Adversarial Loss Target: 0.0007\n",
      "Epoch 8, Batch 25/34, Total Loss: 0.5782, Segmentation Loss: 0.0545, Domain Loss Source: 0.1679, Domain Loss Target: 0.3700, Adversarial Loss Target: 0.0007\n",
      "Epoch 8, Batch 30/34, Total Loss: 0.6419, Segmentation Loss: 0.0742, Domain Loss Source: 0.2130, Domain Loss Target: 0.3208, Adversarial Loss Target: 0.0008\n",
      "Epoch 8, Train Loss: 1.7870\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.8856, Recall: 0.7170, F1 Score: 0.7909, Dice Score: 0.7909, Accuracy: 0.9346\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.4686, Recall: 0.6956, F1 Score: 0.5524, Dice Score: 0.5524, Accuracy: 0.7770\n",
      "Epoch 8, Validation Loss Source: 0.2868, Validation Loss Target: 1.2194\n",
      "Epoch 9, Batch 5/34, Total Loss: 0.6757, Segmentation Loss: 0.1497, Domain Loss Source: 0.1566, Domain Loss Target: 0.3867, Adversarial Loss Target: 0.0005\n",
      "Epoch 9, Batch 10/34, Total Loss: 0.6312, Segmentation Loss: 0.0782, Domain Loss Source: 0.2405, Domain Loss Target: 0.2605, Adversarial Loss Target: 0.0008\n",
      "Epoch 9, Batch 15/34, Total Loss: 0.6360, Segmentation Loss: 0.0723, Domain Loss Source: 0.3070, Domain Loss Target: 0.2473, Adversarial Loss Target: 0.0010\n",
      "Epoch 9, Batch 20/34, Total Loss: 0.6113, Segmentation Loss: 0.0698, Domain Loss Source: 0.2140, Domain Loss Target: 0.3264, Adversarial Loss Target: 0.0007\n",
      "Epoch 9, Batch 25/34, Total Loss: 0.5576, Segmentation Loss: 0.0516, Domain Loss Source: 0.3048, Domain Loss Target: 0.1858, Adversarial Loss Target: 0.0011\n",
      "Epoch 9, Batch 30/34, Total Loss: 0.5571, Segmentation Loss: 0.0695, Domain Loss Source: 0.2765, Domain Loss Target: 0.1914, Adversarial Loss Target: 0.0012\n",
      "Epoch 9, Train Loss: 1.7938\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.8746, Recall: 0.7315, F1 Score: 0.7953, Dice Score: 0.7953, Accuracy: 0.9349\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.4636, Recall: 0.7127, F1 Score: 0.5551, Dice Score: 0.5551, Accuracy: 0.7733\n",
      "Epoch 9, Validation Loss Source: 0.2934, Validation Loss Target: 1.2606\n",
      "Epoch 10, Batch 5/34, Total Loss: 0.5639, Segmentation Loss: 0.1441, Domain Loss Source: 0.3979, Domain Loss Target: 0.1512, Adversarial Loss Target: 0.0013\n",
      "Epoch 10, Batch 10/34, Total Loss: 0.5923, Segmentation Loss: 0.0762, Domain Loss Source: 0.1243, Domain Loss Target: 0.5616, Adversarial Loss Target: 0.0004\n",
      "Epoch 10, Batch 15/34, Total Loss: 0.6097, Segmentation Loss: 0.0684, Domain Loss Source: 0.4138, Domain Loss Target: 0.1804, Adversarial Loss Target: 0.0012\n",
      "Epoch 10, Batch 20/34, Total Loss: 0.5662, Segmentation Loss: 0.0652, Domain Loss Source: 0.1753, Domain Loss Target: 0.2856, Adversarial Loss Target: 0.0008\n",
      "Epoch 10, Batch 25/34, Total Loss: 0.5776, Segmentation Loss: 0.0495, Domain Loss Source: 0.3864, Domain Loss Target: 0.1082, Adversarial Loss Target: 0.0017\n",
      "Epoch 10, Batch 30/34, Total Loss: 0.5642, Segmentation Loss: 0.0674, Domain Loss Source: 0.2586, Domain Loss Target: 0.2290, Adversarial Loss Target: 0.0010\n",
      "Epoch 10, Train Loss: 1.6771\n",
      "Evaluating model performance on source data\n",
      "Precision: 0.8729, Recall: 0.7408, F1 Score: 0.8001, Dice Score: 0.8001, Accuracy: 0.9360\n",
      "Evaluating model performance on target data\n",
      "Precision: 0.4745, Recall: 0.6805, F1 Score: 0.5523, Dice Score: 0.5523, Accuracy: 0.7825\n",
      "Epoch 10, Validation Loss Source: 0.2972, Validation Loss Target: 1.2639\n",
      "Precision: 0.4636, Recall: 0.7127, F1 Score: 0.5551, Dice Score: 0.5551, Accuracy: 0.7733\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33641f2164d743f7b4c1a37a5124e624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3142.925 MB of 3142.925 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dice_score/source</td><td></td></tr><tr><td>dice_score/target</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>precision/source</td><td></td></tr><tr><td>precision/target</td><td></td></tr><tr><td>test/accuracy</td><td></td></tr><tr><td>test/dice_score</td><td></td></tr><tr><td>test/f1_score</td><td></td></tr><tr><td>test/precision</td><td></td></tr><tr><td>test/recall</td><td></td></tr><tr><td>train/domain_loss</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>val/loss_source</td><td></td></tr><tr><td>val/loss_target</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dice_score/source</td><td>0.80011</td></tr><tr><td>dice_score/target</td><td>0.55234</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>precision/source</td><td>0.87293</td></tr><tr><td>precision/target</td><td>0.47449</td></tr><tr><td>test/accuracy</td><td>0.77335</td></tr><tr><td>test/dice_score</td><td>0.55514</td></tr><tr><td>test/f1_score</td><td>0.55514</td></tr><tr><td>test/precision</td><td>0.46362</td></tr><tr><td>test/recall</td><td>0.71265</td></tr><tr><td>train/domain_loss</td><td>0.51002</td></tr><tr><td>train/loss</td><td>1.67708</td></tr><tr><td>val/loss_source</td><td>0.2972</td></tr><tr><td>val/loss_target</td><td>1.26391</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">FADA-Linknet-timm-regnetx_320-gcr_comic-sweep_pretrained-augmented_target-random_crops_bloodvessel_ratio01-unsupervised</strong> at: <a href='https://wandb.ai/idp2024/domain-adaptation/runs/9ebzcxi7' target=\"_blank\">https://wandb.ai/idp2024/domain-adaptation/runs/9ebzcxi7</a><br/> View project at: <a href='https://wandb.ai/idp2024/domain-adaptation' target=\"_blank\">https://wandb.ai/idp2024/domain-adaptation</a><br/>Synced 5 W&B file(s), 180 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250115_115413-9ebzcxi7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from FADA.train_FADA_unsupervised import model_pipeline\n",
    "import torch\n",
    "from dataset import build_hsi_dataloader, build_hsi_testloader, build_FIVES_random_crops_dataloaders\n",
    "\n",
    "trainloader_source, validationloader_source, testloader_source = (\n",
    "    build_FIVES_random_crops_dataloaders(\n",
    "        batch_size=16,\n",
    "        num_channels=3,\n",
    "        load_from_path='data/FIVES_random_crops_threshold01'\n",
    "    )\n",
    ")\n",
    "\n",
    "trainloader_hsi = build_hsi_dataloader(\n",
    "    batch_size=8,\n",
    "    train_split=1,\n",
    "    val_split=0,\n",
    "    test_split=0,\n",
    "    exclude_labeled_data=True,\n",
    "    augmented=True,\n",
    ")[0]\n",
    "\n",
    "testloader_hsi = build_hsi_testloader()\n",
    "\n",
    "encoder = \"timm-regnetx_320\"\n",
    "architecture = \"Linknet\"\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "loss = \"BCE\"\n",
    "in_channels = 3\n",
    "ndf = 512\n",
    "learning_rate_fea = 0.007053148664641283\n",
    "learning_rate_cls = 0.0014884108364363155\n",
    "learning_rate_dis = 0.00043925067706149473\n",
    "\n",
    "config = {\n",
    "    \"model\": \"FADA-{architecture}-{encoder}-gcr_comic-sweep_pretrained-augmented_target-random_crops_bloodvessel_ratio01-unsupervised\".format(\n",
    "        architecture=architecture, encoder=encoder\n",
    "    ),\n",
    "    \"encoder\": encoder,\n",
    "    \"architecture\": architecture,\n",
    "    \"in_channels\": in_channels,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"batch_size_source\": trainloader_source.batch_size,\n",
    "    \"batch_size_target\": trainloader_hsi.batch_size,\n",
    "    \"learning_rate_fea\": learning_rate_fea,\n",
    "    \"learning_rate_cls\": learning_rate_cls,\n",
    "    \"learning_rate_dis\": learning_rate_dis,\n",
    "    \"ndf\": ndf,\n",
    "    \"epochs\": epochs,\n",
    "    \"seg_loss\": loss,\n",
    "    \"pretrained\": \"./models/serene-sweep-9.pth\",\n",
    "    \"target_augmented\": True,\n",
    "    \"gaussian\": 'models/gcr_comic-sweep.pth',\n",
    "    \"mu_gaussian\": [334.19, 266.26, 131.40],\n",
    "    \"sigma_gaussian\": [2.92, 2.02, 2.00],\n",
    "}\n",
    "\n",
    "model, train_losses, domain_losses, val_losses_source, val_losses_target = (\n",
    "    model_pipeline(\n",
    "        trainloader_source,\n",
    "        validationloader_source,\n",
    "        testloader_source,\n",
    "        trainloader_hsi,\n",
    "        testloader_hsi,\n",
    "        config,\n",
    "        project=\"domain-adaptation\",\n",
    "        device=device,\n",
    "        batch_print=5,\n",
    "        evaluate=True,\n",
    "        with_overlays=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label=\"Combined Training Loss\")\n",
    "plt.plot(domain_losses, label=\"Domain Loss\")\n",
    "plt.plot(val_losses_source, label=\"Validation Loss Source\")\n",
    "plt.plot(val_losses_target, label=\"Validation Loss Target\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Curves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtim-mach\u001b[0m (\u001b[33midp2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/home/tim_ivan/idp/wandb/run-20250106_183404-fe2610p1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idp2024/hsi-autoencoder/runs/fe2610p1' target=\"_blank\">convReducer</a></strong> to <a href='https://wandb.ai/idp2024/hsi-autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idp2024/hsi-autoencoder' target=\"_blank\">https://wandb.ai/idp2024/hsi-autoencoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idp2024/hsi-autoencoder/runs/fe2610p1' target=\"_blank\">https://wandb.ai/idp2024/hsi-autoencoder/runs/fe2610p1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 5, Loss: 0.3534\n",
      "Epoch 1, Train Loss: 0.3321\n",
      "Epoch 1, Validation Loss: 0.5521\n",
      "Epoch 2, Batch 5, Loss: 68.4464\n",
      "Epoch 2, Train Loss: 38.1581\n",
      "Epoch 2, Validation Loss: 0.5897\n",
      "Epoch 3, Batch 5, Loss: 0.2826\n",
      "Epoch 3, Train Loss: 0.3083\n",
      "Epoch 3, Validation Loss: 0.5497\n",
      "Epoch 4, Batch 5, Loss: 9.5290\n",
      "Epoch 4, Train Loss: 5.4296\n",
      "Epoch 4, Validation Loss: 0.5457\n",
      "Epoch 5, Batch 5, Loss: 2.1078\n",
      "Epoch 5, Train Loss: 1.2938\n",
      "Epoch 5, Validation Loss: 0.5238\n",
      "Epoch 6, Batch 5, Loss: 0.2620\n",
      "Epoch 6, Train Loss: 0.2701\n",
      "Epoch 6, Validation Loss: 0.5040\n",
      "Epoch 7, Batch 5, Loss: 0.2863\n",
      "Epoch 7, Train Loss: 0.2679\n",
      "Epoch 7, Validation Loss: 0.4993\n",
      "Epoch 8, Batch 5, Loss: 56.5798\n",
      "Epoch 8, Train Loss: 31.5554\n",
      "Epoch 8, Validation Loss: 0.6629\n",
      "Epoch 9, Batch 5, Loss: 0.3270\n",
      "Epoch 9, Train Loss: 0.3380\n",
      "Epoch 9, Validation Loss: 0.6395\n",
      "Epoch 10, Batch 5, Loss: 0.2751\n",
      "Epoch 10, Train Loss: 0.2847\n",
      "Epoch 10, Validation Loss: 0.5216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a72ff9aec04e9babc3b936d90d0a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.864 MB of 0.864 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>validation/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train/loss</td><td>0.28467</td></tr><tr><td>validation/loss</td><td>0.52159</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">convReducer</strong> at: <a href='https://wandb.ai/idp2024/hsi-autoencoder/runs/fe2610p1' target=\"_blank\">https://wandb.ai/idp2024/hsi-autoencoder/runs/fe2610p1</a><br/> View project at: <a href='https://wandb.ai/idp2024/hsi-autoencoder' target=\"_blank\">https://wandb.ai/idp2024/hsi-autoencoder</a><br/>Synced 5 W&B file(s), 10 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250106_183404-fe2610p1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(ConvAutoEncoder(\n",
       "   (encoder): ConvReducer(\n",
       "     (conv1x1): Conv2d(826, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "   )\n",
       "   (decoder): Sequential(\n",
       "     (0): Conv2d(3, 826, kernel_size=(1, 1), stride=(1, 1))\n",
       "   )\n",
       " ),\n",
       " [0.33212346500820583,\n",
       "  38.15814441608058,\n",
       "  0.3083326352967156,\n",
       "  5.429602690868908,\n",
       "  1.2937968108389113,\n",
       "  0.27008532815509373,\n",
       "  0.26786717110209995,\n",
       "  31.555382001731132,\n",
       "  0.33804674943288165,\n",
       "  0.2846721609433492],\n",
       " [0.5520845353603363,\n",
       "  0.5896639406681061,\n",
       "  0.5497033417224884,\n",
       "  0.5457060217857361,\n",
       "  0.5238021850585938,\n",
       "  0.5040395379066467,\n",
       "  0.49933808743953706,\n",
       "  0.6628828555345535,\n",
       "  0.6394935458898544,\n",
       "  0.5215946286916733])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import build_hsi_dataloader, HSIDataset, build_hsi_testloader\n",
    "from dimensionality_reduction.autoencoder import (\n",
    "    ConvAutoEncoder,\n",
    "    model_pipeline_autoencoder,\n",
    ")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainloader_hsi = build_hsi_dataloader(\n",
    "    batch_size=8,\n",
    "    train_split=1,\n",
    "    val_split=0,\n",
    "    test_split=0,\n",
    "    exclude_labeled_data=True,\n",
    "    augmented=True,\n",
    ")[0]\n",
    "\n",
    "testloader_hsi = build_hsi_testloader()\n",
    "\n",
    "lr = 0.001\n",
    "gaussian = ConvAutoEncoder()\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(gaussian.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"model\": \"convReducer\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": lr,\n",
    "    \"batch_size\": trainloader_hsi.batch_size,\n",
    "    \"epochs\": 10,\n",
    "}\n",
    "\n",
    "model_pipeline_autoencoder(\n",
    "    gaussian,\n",
    "    trainloader_hsi,\n",
    "    testloader_hsi,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    config,\n",
    "    project=\"hsi-autoencoder\",\n",
    "    device=device,\n",
    "    model_name=\"convReducer\",\n",
    "    batch_print=5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
