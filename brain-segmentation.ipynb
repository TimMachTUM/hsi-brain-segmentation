{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from dataset import HSIDataset\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "path = '../../home/ivan/HELICoiD/HSI_Human_Brain_Database_IEEE_Access/'\n",
    "\n",
    "dataset = HSIDataset(path)\n",
    "dataset.normalize_dataset()\n",
    "\n",
    "# Segmentation Model Split\n",
    "# train_indices = list(range(0, 19))\n",
    "# val_indices = list(range(19, 24))\n",
    "# test_indices = list(range(24, 36))\n",
    "\n",
    "# Autoencoder Split\n",
    "train_indices = list(range(0, 33))\n",
    "val_indices = list(range(33, 35))\n",
    "test_indices = list(range(35, 36))\n",
    "\n",
    "trainset = Subset(dataset, train_indices)\n",
    "valset = Subset(dataset, val_indices)\n",
    "testset = Subset(dataset, test_indices)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=2, shuffle=True)\n",
    "validationloader = DataLoader(valset, batch_size=2, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient = \"012-02\"\n",
    "#patient = \"025-02\"\n",
    "#patient = \"015-01\"\n",
    "# patient = \"012-01\"\n",
    "#patient = \"016-04\"\n",
    "#patient = \"008-01\"\n",
    "# patient = \"020-01\"\n",
    "patient = \"004-02\"\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "import glob\n",
    "import pickle\n",
    "from scipy.linalg import pinv\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from skimage import filters, color, io\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import skimage\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from matplotlib.colors import Normalize\n",
    "from PIL import Image\n",
    "from spectral import open_image\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "# left=140\n",
    "# right=280\n",
    "#left=200\n",
    "#right=201\n",
    "left=520\n",
    "right=670\n",
    "\n",
    "\n",
    "hdr_path = path+\"/{}/raw.hdr\".format(patient)\n",
    "img = open_image(hdr_path)\n",
    "wavelength = np.array(img.metadata['wavelength']).astype(float)\n",
    "print(wavelength[left])\n",
    "print(wavelength[right])\n",
    "# print(np.where((wavelength >= 700) & (wavelength <= 900))[0])\n",
    "\n",
    "white_path = path+\"/{}/whiteReference.hdr\".format(patient)\n",
    "white = open_image(white_path)\n",
    "white = white.load()\n",
    "\n",
    "dark_path = path+\"/{}/darkReference.hdr\".format(patient)\n",
    "\n",
    "dark = open_image(dark_path)\n",
    "dark = dark.load()\n",
    "\n",
    "white_full = np.tile(white, (img.shape[0],1,1))\n",
    "dark_full = np.tile(dark, (img.shape[0],1,1))\n",
    "\n",
    "img_normalized = ((img.load() - dark_full) / (white_full - dark_full))\n",
    "#img_normalized = ((img.load() - dark_full) / (white_full - dark_full))+0.1\n",
    "img_normalized[img_normalized <= 0] = 10**-2\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(16, 8))\n",
    "axs[0].imshow(np.median(img_normalized,axis=2))\n",
    "axs[0].set_title(\"Median across all wavelengths\")\n",
    "median_hb = (np.median(img_normalized[:,:,left:right],axis=2))\n",
    "median_hb_normalized = (median_hb - np.min(median_hb))/(np.max(median_hb) - np.min(median_hb))\n",
    "plt2 = axs[1].imshow(median_hb_normalized, vmax=0.05)\n",
    "axs[1].set_title(\"Median from \" + str(wavelength[left]) + \"nm to \" + str(wavelength[right]) + \"nm (vmax=0.05)\")\n",
    "axs[2].imshow((median_hb_normalized > filters.threshold_sauvola(median_hb_normalized)), cmap='gray')\n",
    "axs[2].set_title(\"Segmentation map using Sauvola Thresholding\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig(plot_dir + \"segm\")\n",
    "#plt3 = axs[2].imshow((median_hb < 0.3)*median_hb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_labels(labels):\n",
    "    plt.imshow(labels.squeeze().numpy(), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def create_montage(dataset, num_images=10):\n",
    "    # Define the number of images you want to show in the montage\n",
    "    num_images = min(num_images, len(dataset))\n",
    "\n",
    "    fig, axes = plt.subplots(num_images, 2, figsize=(10, num_images * 5))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        sample = dataset[i]\n",
    "        image, label = sample[2], sample[1]\n",
    "        \n",
    "        # Convert image and label to numpy arrays for plotting\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.numpy().transpose(1, 2, 0)\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            label = label.numpy().squeeze()\n",
    "            overlay = np.zeros_like(image)\n",
    "            overlay[label == 1] = [0, 255, 0]\n",
    "        \n",
    "        # Plot the image\n",
    "        axes[i, 0].imshow(image)\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 0].set_title('Image {i}'.format(i=i))\n",
    "        \n",
    "        # Plot the label\n",
    "        axes[i, 1].imshow(label, cmap='gray')\n",
    "        axes[i, 1].axis('off')\n",
    "        axes[i, 1].set_title('Label')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "create_montage(dataset, num_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn as nn\n",
    "from segmentation_util import model_pipeline\n",
    "import torch.nn.functional as F\n",
    "from HSI_Net import HyperspectralToGrayscale, CombinedModel, ConvolutionalReducer, Unet\n",
    "\n",
    "config = {\n",
    "    'model': 'Test-model',\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 10,\n",
    "    'batch_size': 1,\n",
    "    'optimizer': 'Adam',\n",
    "    'criterion': 'BCELoss',\n",
    "}\n",
    "\n",
    "segmenter = smp.Unet('resnet34', in_channels=1, classes=1)\n",
    "segmenter.load_state_dict(torch.load('./models/Unet-resnet34-DiceLoss/Unet-resnet34-DiceLoss_epoch10.pth'))\n",
    "encoder = HyperspectralToGrayscale()\n",
    "model = CombinedModel(encoder, segmenter)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from segmentation_util import model_pipeline\n",
    "\n",
    "\n",
    "model, train_losses, val_losses = model_pipeline(model, trainloader=trainloader, \n",
    "                                                 validationloader=validationloader, \n",
    "                                                 testloader=testloader, criterion=criterion, \n",
    "                                                 optimizer=optimizer,project='hsi-segmentation',\n",
    "                                                 model_name=config['model'],\n",
    "                                                 device=device, config=config, \n",
    "                                                 batch_print=1)\n",
    "\n",
    "# Plotting the training and validation loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from HSI_Net import CombinedModel, HyperspectralToGrayscale, ConvolutionalReducer\n",
    "from segmentation_util import predict, show_overlay\n",
    "import segmentation_models_pytorch as smp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "encoder = HyperspectralToGrayscale()\n",
    "segmenter = smp.Unet('resnet34', in_channels=1, classes=1)\n",
    "# segmenter.load_state_dict(torch.load('./models/Unet-resnet34-DiceLoss/Unet-resnet34-DiceLoss_epoch10.pth'))\n",
    "model = CombinedModel(encoder, segmenter)\n",
    "model.load_state_dict(torch.load('./models/ConvLayer-Unet-resnet34/ConvLayer-Unet-resnet34_epoch10.pth'))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "show_overlay(model, testset[0], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Approach:\n",
    "## Standard Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import model_pipeline_autoencoder, Autoencoder\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "config = {\n",
    "    'model': 'autoencoder-single-channel-with-normalized-cropped-data-deeper',\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 10,\n",
    "    'batch_size': trainloader.batch_size,\n",
    "    'optimizer': 'Adam',\n",
    "    'criterion': 'MSELoss',\n",
    "}\n",
    "\n",
    "autoencoder = Autoencoder(output_channels=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=config['learning_rate'])\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "autoencoder, train_losses, val_losses = model_pipeline_autoencoder(autoencoder,\n",
    "                                                trainloader=trainloader, \n",
    "                                                validationloader=validationloader, \n",
    "                                                criterion=criterion, \n",
    "                                                optimizer=optimizer,\n",
    "                                                project='hsi-autoencoder',\n",
    "                                                model_name=config['model'],\n",
    "                                                device=device, \n",
    "                                                config=config, \n",
    "                                                batch_print=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import model_pipeline_variational_autoencoder, VariationalAutoencoder\n",
    "from torchsummary import summary\n",
    "\n",
    "config = {\n",
    "    'model': 'variational-autoencoder',\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 10,\n",
    "    'batch_size': trainloader.batch_size,\n",
    "    'optimizer': 'Adam',\n",
    "    'criterion': 'vae_loss',\n",
    "}\n",
    "\n",
    "vae = VariationalAutoencoder()\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=config['learning_rate'])\n",
    "device = torch.device('cuda:6' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "vae, train_losses, val_losses = model_pipeline_variational_autoencoder(vae,\n",
    "                                                trainloader=trainloader, \n",
    "                                                validationloader=validationloader, \n",
    "                                                optimizer=optimizer,\n",
    "                                                project='hsi-autoencoder',\n",
    "                                                model_name=config['model'],\n",
    "                                                device=device, \n",
    "                                                config=config, \n",
    "                                                batch_print=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model Approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HSI_Net import CombinedModel, SegmentationModelWithWindowing\n",
    "from segmentation_util import predict, show_overlay, build_segmentation_model\n",
    "from autoencoder import Autoencoder, DeeperAutoencoder\n",
    "from ensemble_model import EnsembleModelMajorityVoting, EnsembleModelAverage, EnsembleModelAbsoluteVoting\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "\n",
    "device = ('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[35]\n",
    "\n",
    "autoencoder_single_channel = Autoencoder(output_channels=1)\n",
    "autoencoder_single_channel.load_state_dict(torch.load('./models/autoencoder-single-channel-with-normalized-cropped-data.pth'))\n",
    "autoencoder_single_channel.to(device)\n",
    "autoencoder_single_channel.eval()\n",
    "\n",
    "encoder = 'timm-regnetx_320'\n",
    "architecture = 'Linknet'\n",
    "\n",
    "segmenter_single_channel = build_segmentation_model(encoder, architecture, device)\n",
    "segmenter_single_channel.load_state_dict(torch.load('./models/{architecture}-{encoder}-512x512-augmented-with-random-crops-single-channel-focal.pth'.format(architecture=architecture, encoder=encoder)))\n",
    "segmenter_single_channel.eval()\n",
    "\n",
    "window_full = (400, 1100)\n",
    "model_window_full = SegmentationModelWithWindowing(segmenter_single_channel, window=dataset.get_window_from_wavelengths(window_full))\n",
    "\n",
    "window1 = (700, 900)\n",
    "model_windowing_700to900 = SegmentationModelWithWindowing(segmenter_single_channel, window=dataset.get_window_from_wavelengths(window1))\n",
    "\n",
    "\n",
    "window2 = (500, 600)\n",
    "# segmenter_windowed = smp.UnetPlusPlus('resnext101_32x8d', in_channels=1, classes=1)\n",
    "# segmenter_windowed.load_state_dict(torch.load('./models/UnetPlusPlus-resnext101_32x8d-512x512-augmented-with-random-crops-single-channel.pth'))\n",
    "# segmenter_windowed.to(device)\n",
    "\n",
    "model_with_windowing_500to600 = SegmentationModelWithWindowing(segmenter_single_channel, window=dataset.get_window_from_wavelengths(window2))\n",
    "\n",
    "window3 = (540, 580)\n",
    "window4 = (620, 650)\n",
    "window5 = (900, 950)\n",
    "\n",
    "model_windowing_540to580 = SegmentationModelWithWindowing(segmenter_single_channel, window=dataset.get_window_from_wavelengths(window3))\n",
    "model_windowing_620to650 = SegmentationModelWithWindowing(segmenter_single_channel, window=dataset.get_window_from_wavelengths(window4))\n",
    "model_windowing_900to1000 = SegmentationModelWithWindowing(segmenter_single_channel, window=dataset.get_window_from_wavelengths(window5))\n",
    "model_autoencoder = CombinedModel(autoencoder_single_channel.encoder, segmenter_single_channel)\n",
    "\n",
    "threshold = 0.6\n",
    "\n",
    "show_overlay(model_window_full, data, device, title='Reduction with averaging over full window and segmentation with {architecture} {encoder}'.format(architecture=architecture, encoder=encoder), threshold=threshold)\n",
    "\n",
    "show_overlay(model_autoencoder, data, device, title='Autoencoder', threshold=threshold)\n",
    "\n",
    "show_overlay(model_with_windowing_500to600, data, device, title='Reduction with averaging over window {window2} nm and segmentation with {architecture} {encoder}'.format(window2=window2, architecture=architecture, encoder=encoder), threshold=threshold)\n",
    "show_overlay(model_windowing_700to900, data, device, title='Reduction with averaging over window from {window1} nm and segmentation with {architecture} {encoder}'.format(window1=window1, architecture=architecture, encoder=encoder), threshold=threshold)\n",
    "show_overlay(model_windowing_540to580, data, device, title='Reduction with averaging over window from {window3} nm and segmentation with {architecture} {encoder}'.format(window3=window3, architecture=architecture, encoder=encoder), threshold=threshold)\n",
    "show_overlay(model_windowing_620to650, data, device, title='Reduction with averaging over window from {window4} nm and segmentation with {architecture} {encoder}'.format(window4=window4, architecture=architecture, encoder=encoder), threshold=threshold)\n",
    "show_overlay(model_windowing_900to1000, data, device, title='Reduction with averaging over window from {window5} nm and segmentation with {architecture} {encoder}'.format(window5=window5, architecture=architecture, encoder=encoder), threshold=threshold)\n",
    "\n",
    "\n",
    "model = EnsembleModelAbsoluteVoting([model_with_windowing_500to600, model_windowing_700to900, model_windowing_540to580, model_windowing_620to650, model_windowing_900to1000, model_window_full])\n",
    "output = model_window_full(data[0].unsqueeze(0).to(device))\n",
    "\n",
    "show_overlay(model, data, device, with_sigmoid=False, title='Ensemble model with absolute voting', threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of different Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HSI_Net import CombinedModel, SegmentationModelWithWindowing\n",
    "from segmentation_util import predict, show_overlay, build_segmentation_model, show_interactive_overlay\n",
    "from autoencoder import Autoencoder, DeeperAutoencoder\n",
    "from ensemble_model import EnsembleModelMajorityVoting, EnsembleModelAverage, EnsembleModelAbsoluteVoting\n",
    "import segmentation_models_pytorch as smp\n",
    "from ipywidgets import FloatSlider, interact, fixed\n",
    "import torch\n",
    "\n",
    "device = ('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0]\n",
    "\n",
    "encoder = 'timm-regnetx_320'\n",
    "architecture = 'Linknet'\n",
    "\n",
    "segmenter_single_channel = build_segmentation_model(encoder, architecture, device)\n",
    "segmenter_single_channel.load_state_dict(torch.load('./models/{architecture}-{encoder}-512x512-augmented-with-random-crops-single-channel-focal.pth'.format(architecture=architecture, encoder=encoder)))\n",
    "segmenter_single_channel.eval()\n",
    "\n",
    "window = (400, 1000)\n",
    "model_with_windowing = SegmentationModelWithWindowing(segmenter_single_channel, window=dataset.get_window_from_wavelengths(window))\n",
    "title = 'Reduction with averaging over window {window} and segmentation with {architecture} {encoder}'.format(window=window, architecture=architecture, encoder=encoder)\n",
    "\n",
    "show_interactive_overlay(model_with_windowing, data, device, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Approach:\n",
    "The approach is to leverage transfer learning on eye fundus scans which are well labeled and look kind of similar to the bloodvessels inside the brain.\n",
    "\n",
    "We use an autoencoder and input both the hsi scan and an eye fundus scan for dimensionality reduction of the hsi scan to one channel and also learning the structure of the bloodvessels with eye fundus scans and then use the pretrained model of the eye fundus scans.\n",
    "\n",
    "Two branches:\n",
    "- Input reduced hsi scans -> Reconstruct them\n",
    "- Input FIVES images -> use loss of the groundtruth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from dataset import HSIDataset\n",
    "from dataset import SegmentationDataset, SegmentationDatasetWithRandomCrops\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "from torchvision.transforms import Compose, ToTensor, Grayscale, Resize\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as v2\n",
    "import itertools\n",
    "\n",
    "path = '../../home/ivan/HELICoiD/HSI_Human_Brain_Database_IEEE_Access/'\n",
    "\n",
    "dataset = HSIDataset(path)\n",
    "dataset.normalize_dataset()\n",
    "\n",
    "# Autoencoder Split\n",
    "train_indices = list(range(0, 32))\n",
    "val_indices = list(range(32, 34))\n",
    "test_indices = list(range(34, 36))\n",
    "\n",
    "trainset_hsi = Subset(dataset, train_indices)\n",
    "valset_hsi = Subset(dataset, val_indices)\n",
    "testset_hsi = Subset(dataset, test_indices)\n",
    "\n",
    "trainloader_hsi = DataLoader(trainset_hsi, batch_size=2, shuffle=True)\n",
    "trainloader_hsi = itertools.cycle(trainloader_hsi)\n",
    "validationloader_hsi = DataLoader(valset_hsi, batch_size=2, shuffle=False)\n",
    "testloader_hsi = DataLoader(testset_hsi, batch_size=2, shuffle=False)\n",
    "\n",
    "train_image_path = './FIVES/train/Original'\n",
    "train_label_path = './FIVES/train/GroundTruth'\n",
    "test_image_path = './FIVES/test/Original'\n",
    "test_label_path = './FIVES/test/GroundTruth'\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define transformations for images\n",
    "image_transform = Compose([\n",
    "    Grayscale(num_output_channels=1),  # Convert the image to grayscale\n",
    "    Resize((512, 512)),                # Resize images to 512x512\n",
    "    ToTensor(),                         # Convert the image to a PyTorch tensor\n",
    "    # Normalize(mean=[0.3728, 0.1666, 0.0678], std=[0.1924, 0.0956, 0.0395])\n",
    "    # Normalize(mean=[0.2147], std=[0.1163])   # Normalize the grayscale image\n",
    "])\n",
    "\n",
    "# Define transformations for labels, if needed\n",
    "label_transform = Compose([\n",
    "    Resize((512, 512)),  # Resize labels to 512x512\n",
    "    ToTensor()           # Convert label to a tensor\n",
    "])\n",
    "\n",
    "dataset = SegmentationDataset(\n",
    "    train_image_path, \n",
    "    train_label_path, \n",
    "    image_transform, \n",
    "    label_transform,\n",
    ")\n",
    "\n",
    "testset = SegmentationDataset(\n",
    "    test_image_path, \n",
    "    test_label_path, \n",
    "    image_transform, \n",
    "    label_transform\n",
    ")\n",
    "\n",
    "# Prepare DataLoader\n",
    "dataset, _ = random_split(dataset, [105, len(dataset) - 105])\n",
    "train_size, val_size = int(0.9 * len(dataset)), int(0.1 * len(dataset) + 1)\n",
    "train_indices = np.random.choice(len(dataset), train_size, replace=False)\n",
    "val_indices = np.setdiff1d(np.arange(len(dataset)), train_indices)\n",
    "\n",
    "train_dataset_fundus = Subset(dataset, train_indices)\n",
    "val_dataset_fundus = Subset(dataset, val_indices)\n",
    "\n",
    "\n",
    "print(f'Number of samples in the training set: {len(train_dataset_fundus)}, validation set: {len(val_dataset_fundus)}')\n",
    "print(f'Number of samples in the test set: {len(testset)}')\n",
    "\n",
    "trainloader_fundus = DataLoader(train_dataset_fundus, batch_size=4, shuffle=True, num_workers=8)\n",
    "validationloader_fundus = DataLoader(val_dataset_fundus, batch_size=4, shuffle=False, num_workers=8)\n",
    "testloader_fundus = DataLoader(testset, batch_size=4, shuffle=False, num_workers=8)\n",
    "\n",
    "print(len(trainloader_fundus), len(validationloader_fundus), len(testloader_fundus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "def train_and_validate(encoder, segmenter, trainloader_hsi, trainloader_fundus, validationloader_hsi, validationloader_fundus, criterion_hsi, criterion_fundus, optimizer_encoder, optimizer_fundus, epochs=10, model_name=None, device='cuda', batch_print=10):\n",
    "    \"\"\"\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param segmenter: segmenter to train and validate\n",
    "        :param loss_criterion: Loss Criterion_fundus to minimize\n",
    "        :param optimizer_fundus: Optimizer_fundus for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "        :param model_name: model file name (default=None)\n",
    "    Returns\n",
    "        train_losses, val_losses: List of losses per epoch\n",
    "    \"\"\"\n",
    "    train_losses, val_losses = [], []\n",
    "    min_val_loss = np.inf\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        segmenter.train()\n",
    "        encoder.train()\n",
    "        segmenter.to(device)\n",
    "        encoder.to(device)\n",
    "        running_loss = 0.0\n",
    "        train_loss = 0.0\n",
    "        for i, (hsi_data, fundus_data) in enumerate(zip(trainloader_hsi, trainloader_fundus)):\n",
    "            fundus_img, labels_labels = fundus_data[0].to(device), fundus_data[1].to(device).float()\n",
    "            outputs_fundus = segmenter(fundus_img)\n",
    "            optimizer_fundus.zero_grad()\n",
    "            loss_fundus = criterion_fundus(outputs_fundus, labels_labels)\n",
    "            loss_fundus.backward()\n",
    "            optimizer_fundus.step()\n",
    "\n",
    "            hsi_img = hsi_data[0].to(device)\n",
    "            reduced_hsi = encoder(hsi_img)\n",
    "            outputs_hsi = segmenter(reduced_hsi)\n",
    "            optimizer_encoder.zero_grad()\n",
    "            optimizer_fundus.zero_grad()\n",
    "            loss_hsi = criterion_hsi(outputs_hsi, reduced_hsi)\n",
    "            loss_hsi.backward()\n",
    "            optimizer_encoder.step()\n",
    "            optimizer_fundus.step()\n",
    "\n",
    "            running_loss += (loss_fundus.item() + loss_hsi.item()) / 2\n",
    "            train_loss += (loss_fundus.item() + loss_hsi.item()) / 2\n",
    "\n",
    "            if (i + 1) % batch_print == 0:  # Adjust the condition based on your preference\n",
    "                print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / batch_print:.4f}')\n",
    "                running_loss = 0.0  # Reset running loss after printing\n",
    "                \n",
    "        # Calculate and print the average loss per epoch\n",
    "        train_loss = train_loss / (len(trainloader_fundus))\n",
    "        train_losses.append(train_loss)\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}')\n",
    "        # wandb.log({\"epoch\":epoch+1, \"train/loss\": train_loss}, step=epoch+1)\n",
    "        \n",
    "        # Validation phase\n",
    "        segmenter.eval()\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, (hsi_data, fundus_data) in enumerate(zip(validationloader_hsi, validationloader_fundus)):\n",
    "                inputs, labels = fundus_data[0].to(device), fundus_data[1].to(device).float()\n",
    "                outputs = segmenter(inputs)\n",
    "                loss_fundus = criterion_fundus(outputs, labels)\n",
    "\n",
    "                hsi_img = hsi_data[0].to(device)\n",
    "                reduced_hsi = encoder(hsi_img)\n",
    "                outputs_hsi = segmenter(reduced_hsi)\n",
    "                loss_hsi = criterion_hsi(outputs_hsi, reduced_hsi)\n",
    "\n",
    "                val_running_loss += (loss_fundus.item() + loss_hsi.item())/2\n",
    "        \n",
    "        val_loss = val_running_loss / (len(validationloader_fundus))\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if model_name:\n",
    "            if val_loss < min_val_loss:\n",
    "                min_val_loss = val_loss\n",
    "                torch.save(segmenter.state_dict(), f'./models/{model_name}_segmenter.pth')\n",
    "                torch.save(encoder.state_dict(), f'./models/{model_name}_encoder.pth')\n",
    "                # model_artifact = wandb.Artifact(f\"{model_name}\", type=\"model\")\n",
    "                # model_artifact.add_file(f'./models/{model_name}.pth')\n",
    "                # wandb.log_artifact(model_artifact)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}')\n",
    "        # wandb.log({\"epoch\":epoch+1, \"validation/loss\": val_loss}, step=epoch+1)\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from autoencoder import Autoencoder\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "segmenter = smp.Unet('timm-resnest101e', in_channels=1, classes=1)\n",
    "segmenter.load_state_dict(torch.load('./models/Unet-timm-resnest101e-512x512-augmented-with-random-crops-normalized_epoch10.pth'))\n",
    "autoencoder = Autoencoder(output_channels=1)\n",
    "autoencoder.load_state_dict(torch.load('./models/autoencoder-single-channel-with-cropped-data.pth'))\n",
    "\n",
    "config = {\n",
    "    'model': 'DualModel_encoder_with_mse',\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 10,\n",
    "    'batch_size': trainloader_fundus.batch_size,\n",
    "    'optimizer': 'Adam',\n",
    "    'criterion': 'MSELoss, DiceLoss',\n",
    "}\n",
    "\n",
    "autoencoder = Autoencoder(output_channels=1)\n",
    "\n",
    "criterion_hsi = nn.MSELoss()\n",
    "criterion_fundus = smp.losses.DiceLoss(mode='binary')\n",
    "\n",
    "optimizer_fundus = torch.optim.Adam(segmenter.parameters(), lr=config['learning_rate'])\n",
    "optimizer_encoder = torch.optim.Adam(autoencoder.encoder.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_losses, val_losses = train_and_validate(encoder=autoencoder.encoder, \n",
    "                   segmenter=segmenter, \n",
    "                   trainloader_hsi=trainloader_hsi, \n",
    "                   trainloader_fundus=trainloader_fundus, \n",
    "                   validationloader_hsi=validationloader_hsi, \n",
    "                   validationloader_fundus=validationloader_fundus,\n",
    "                   criterion_hsi=criterion_hsi,\n",
    "                   criterion_fundus=criterion_fundus,\n",
    "                   optimizer_encoder=optimizer_encoder,\n",
    "                   optimizer_fundus=optimizer_fundus,\n",
    "                   epochs=10,\n",
    "                   model_name=config['model'],\n",
    "                   device=device,\n",
    "                   batch_print=1)\n",
    "\n",
    "# Plotting the training and validation loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HSI_Net import CombinedModel\n",
    "from segmentation_util import predict, show_overlay\n",
    "import cv2\n",
    "\n",
    "# def show_overlay(model, data, device):\n",
    "#     prediction = predict(model, data[0], device)\n",
    "#     image = data[1].cpu().numpy().squeeze()\n",
    "#     image = np.stack([image, image, image], axis=-1)\n",
    "#     overlay = np.zeros_like(image)\n",
    "#     overlay[prediction.cpu().numpy().squeeze(0) == 1] = [0, 255, 0]\n",
    "#     combined = cv2.addWeighted(image, 0.7, overlay, 0.3, 0)\n",
    "    \n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(combined, cmap='gray')\n",
    "#     plt.axis('off')  # Turn off axis numbers and ticks\n",
    "#     plt.show()\n",
    "\n",
    "segmenter = smp.Unet('timm-resnest101e', in_channels=1, classes=1)\n",
    "segmenter.load_state_dict(torch.load('./models/DualModel_encoder_with_mse_segmenter.pth'))\n",
    "autoencoder = Autoencoder(output_channels=1)\n",
    "autoencoder.encoder.load_state_dict(torch.load('./models/DualModel_encoder_with_mse_encoder.pth'))\n",
    "\n",
    "model = CombinedModel(autoencoder.encoder, segmenter)\n",
    "show_overlay(model, trainset_hsi[22], device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
